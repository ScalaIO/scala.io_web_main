{
    "name": "Xavier Tordoir",
    "bio": "Xavier has a scientific background, with several years in academic research relying on massive data processing (physical sciences, genomics and financial markets). He developed distributed storage and processing solutions before becoming BigData and Data science consultant, and then entrepreneur with a Data science platform project. Author of trainings in Spark, Kafka, Machine learning and Tensorflow, Xavier now works at Lunatech on the development of the BigData and AI branch.",
    "twitter": "xtordoir",
    "company": "Lunatech",
    "url": "http://www.lunatech.com",
    "avatar": "/assets/images/speakers/xavier-tordoir.jpg",
    "talks": [
        {
            "title": "Introduction to Spark in the context of a Distributed Pipeline",
            "description": "Scala is the prime language for distributed computing. Scala developers benefit from gaining expertise in BigData and Data Science frameworks, the goal of this session is to kick-start newcomers to these topics. \r\nThe workshop is structured in such a way that the different components of Spark are introduced and used to build a single complete data pipeline, from data collection to serving Machine learning models. We use historical and streaming cryptocurrency price data as a use case. The training covers the following topics:\r\n\r\n- Distributed computing and storage\r\n- Dataframes and Datasets for batch processing, data cleaning\r\n- Working with parquet files, importance of schemas\r\n- Simple ML: training and saving models, ML Pipelines\r\n- Streaming data, collectors and publishing to Kafka\r\n- Spark and Kafka integration\r\n- Predictions with ML models on a data stream\r\n",
            "abstract": "This hands-on session is a comprehensive introduction to Spark. Using interactive notebooks, attendees learn the concepts and APIs. Covered topics are batch processing with DataFrames, simple Machine Learning and processing a Kafka Stream, building from the ground a complete processing pipeline.",
            "audience_level": "Beginner",
            "talk_format": "Workshop (3 hours)",
            "tags": [
                "Spark",
                "distributed-data-processing",
                "üá¨üáß"
            ]
        },
        {
            "title": "Cas pratiques d'utilisation de Scala Tensorflow pour l'analyse d'images",
            "description": "Nous commencerons par d√©couvrir les concepts de base du Machine Learning appliqu√©s √† la d√©tection d'objets dans des images. \r\nEnsuite, nous √©tudierons deux cas pratiques, √† l'aide de l'API Tensorflow/Scala, en utilisant des mod√®les publi√©s et disponibles dans divers d√©p√¥ts.\r\nNous verrons comment compl√©ter cette d√©tection avec une phase d'anonymisation par floutage des visages et plaques d'immatriculation.\r\nFinalement, nous d√©couvrirons un algorithme permettant de suivre des objets √† travers une vid√©o et nous discuterons des projets OpenSource li√©s √† ces exemples.",
            "abstract": "Nous pr√©sentons l‚Äôutilisation de Tensorflow dans des applications d‚Äôanalyse d‚Äôimages et de vid√©os en Scala. Nous exploitons des mod√®les de d√©tection d‚Äôobjets afin d'anonymiser des images et suivre des objets √† travers une vid√©o.",
            "audience_level": "All",
            "talk_format": "Talk (45 minutes)",
            "tags": [
                "machine-deep-learning",
                "scala",
                "tensorflow",
                "üá´üá∑",
                "deep-learning"
            ]
        }
    ]
}