{
    "name": "Philippe Hong",
    "bio": "Data Engineer",
    "twitter": "h_wki",
    "company": "Univalence",
    "url": "",
    "avatar": "https://secure.gravatar.com/avatar/3d7a342018ef50955b9b244e4de37539?s=500",
    "talks": [
        {
            "title": "Apprivoiser Spark avec ZIO",
            "description": "Avec l'arrivÃ©e imminente de ZIO v1.0, intÃ©ressons-nous plus au nouveau paramÃ¨tre de type R. Pour rappel, ZIO a trois paramÃ¨tres de type : R, E et A avec E le type d'Ã©chec et A le type de succÃ¨s de l'IO (ou la Task selon votre prÃ©fÃ©rence). R est un type oÃ¹ nous pouvons passer un environnement, et une question ressort alors, est-il possible de mettre Spark dedans ? Cela nous permettrait de ne pas avoir des implicit de SparkSession partout, de wrapper les appels Ã  des fonctions Spark Ã  effet dans ZIO et aussi de pouvoir crÃ©er et utiliser des rÃ¨gles Scalafix intÃ©ressantes.\r\nDans ce talk, j'aimerais parler des prÃ©cÃ©dents points ainsi qu'apporter un retour d'expÃ©rience sur le refactoring d'un projet existant avec ZIO ayant Spark pour environnement.",
            "abstract": "ZIO est une bibliothÃ¨que Scala qui a un intÃ©rÃªt croissant, mais dont l'usage n'est pas encore trÃ¨s rÃ©pandu. Ce n'est pourtant pas un outil difficile Ã  utiliser et vous obtiendrez ensuite la pouvoir d'utiliser des for-comprehension partout avec un coulis de Spark.",
            "audience_level": "Intermediate",
            "talk_format": "Talk (45 minutes)",
            "tags": [
                "effect-systems",
                "distributed-data-processing",
                "ğŸ‡«ğŸ‡·"
            ]
        }
    ]
}