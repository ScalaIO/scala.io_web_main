[{"talkType":"Keynote","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>n/a</p>\n","id":"CZV-7132","speakers":[{"name":"Martin Odersky","company":"EPFL","id":"6b12b80e28ace01547216eadbe535c59a684e8d7","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/6b12b80e28ace01547216eadbe535c59a684e8d7","rel":"http://cfp.scala.io/api/profile/speaker","title":"Martin Odersky"},"twitter":"@odersky"}],"title":"Dotty","lang":"en","summary":"n/a"},{"talkType":"Keynote","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>Scala and its ecosystem of libraries have achieved a level of adoption that makes it increasingly challenging to make improvements. We can&#x27;t just make changes to Scala and its popular libraries, because we need to think carefully about how to migrate existing user code. If the cost of migration becomes too great, users may chose to delay upgrading, or opt not upgrade at all.</p>\n<p>In this talk, Bill Venners will explain how we can balance the value of making improvements to the Scala language and libraries with that of maintaining stability and compatibility. He will make the case that it is possible and desirable to make improvements despite having users, and show how accomplish it.</p>\n","id":"IFH-2338","speakers":[{"name":"Bill Venners","company":"Artima","id":"7bda2a1d7a0a0380ba967f5b6097eafdba005a59","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/7bda2a1d7a0a0380ba967f5b6097eafdba005a59","rel":"http://cfp.scala.io/api/profile/speaker","title":"Bill Venners"},"twitter":"@bvenners"}],"title":"Making Software Better, Despite Having Users","lang":"en","summary":"Scala and its ecosystem of libraries have achieved a level of adoption that makes it increasingly challenging to make improvements. We can't just make changes to Scala and its popular libraries, because we need to think carefully about how to migrate existing user code. If the cost of migration becomes too great, users may chose to delay upgrading, or opt not upgrade at all. \r\n\r\nIn this talk, Bill Venners will explain how we can balance the value of making improvements to the Scala language and libraries with that of maintaining stability and compatibility. He will make the case that it is possible and desirable to make improvements despite having users, and show how accomplish it."},{"talkType":"Keynote","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>With the creation of the Scala Center, Scala has achieved a level of open source collaboration that is heretofore unseen, where the worlds of government, academia, corporate enterprise and community are now actively engaging in a positive way to move the language forward in multiple dimensions.  However, most other open source technologies do not have this level of diverse backing, and are in serious danger of losing their ability to meet their long-term potential.</p>\n<p>In this talk, I will explore the reasons open source projects, libraries, tools and more are now in danger of never becoming more than isolated pet projects and islands unto themselves.  I will then discuss how we can change this to allow all of our projects to succeed in the long term.  Is Typelevel an example of this, and how can we all help it succeed?</p>\n","id":"CPK-1474","speakers":[{"name":"Jamie Allen","company":"Starbucks","id":"efd86331afa82d5df80520fc8ba42c679c385258","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/efd86331afa82d5df80520fc8ba42c679c385258","rel":"http://cfp.scala.io/api/profile/speaker","title":"Jamie Allen"},"twitter":"@jamie_allen"}],"title":"FOSS is in Jeopardy","lang":"en","summary":"With the creation of the Scala Center, Scala has achieved a level of open source collaboration that is heretofore unseen, where the worlds of government, academia, corporate enterprise and community are now actively engaging in a positive way to move the language forward in multiple dimensions.  However, most other open source technologies do not have this level of diverse backing, and are in serious danger of losing their ability to meet their long-term potential.\r\n\r\nIn this talk, I will explore the reasons open source projects, libraries, tools and more are now in danger of never becoming more than isolated pet projects and islands unto themselves.  I will then discuss how we can change this to allow all of our projects to succeed in the long term.  Is Typelevel an example of this, and how can we all help it succeed?"},{"talkType":"Short conference","track":"Scala University","audienceLevel":"Débutant","summaryAsHtml":"<p>C&#x27;est quoi un implicit ? Pourquoi ça existe dans le langage ? Le lien au DSL (au fait c&#x27;est quoi un DSL) ? Construire une API en les utilisant...\nCe talk est un 101 des implicits dans le scala.</p>\n","id":"RNF-9275","speakers":[{"name":"Quentin ADAM","company":"Clever Cloud","id":"8c13e04af63fb40ded2e7a7634a4790090d64eca","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/8c13e04af63fb40ded2e7a7634a4790090d64eca","rel":"http://cfp.scala.io/api/profile/speaker","title":"Quentin ADAM"},"twitter":"@waxzce"}],"title":"Implicits: pour faire des APIs simples, des DSL ou de la magie noire, ça marche comment ?","lang":"fr","summary":"C'est quoi un implicit ? Pourquoi ça existe dans le langage ? Le lien au DSL (au fait c'est quoi un DSL) ? Construire une API en les utilisant...\r\nCe talk est un 101 des implicits dans le scala."},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>In this talk I plan to give some techniques of how to get the best out of using Scalacheck, showing tips that might not be immediately apparent to a new or casual user. I’ll explain when to use the Gen and Arbitrary classes, how awesome the new Cogen typeclass actually is, as well as some techniques for debugging and getting the most information out of Scalacheck that you possibly can. I’ll spend some time talking about how using Scalacheck influences the way you design your code and will finish by showing a great way to cut your boilerplate to the very minimum, leaving you to concentrate on the more interesting stuff.</p>\n","id":"DRV-8759","speakers":[{"name":"Noel Markham","company":"47 Degrees","id":"c37add60ff1def667e0b4e666594a14cf4fdd4e5","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/c37add60ff1def667e0b4e666594a14cf4fdd4e5","rel":"http://cfp.scala.io/api/profile/speaker","title":"Noel Markham"},"twitter":"@noelmarkham"}],"title":"Practical ScalaCheck","lang":"en","summary":"In this talk I plan to give some techniques of how to get the best out of using Scalacheck, showing tips that might not be immediately apparent to a new or casual user. I’ll explain when to use the Gen and Arbitrary classes, how awesome the new Cogen typeclass actually is, as well as some techniques for debugging and getting the most information out of Scalacheck that you possibly can. I’ll spend some time talking about how using Scalacheck influences the way you design your code and will finish by showing a great way to cut your boilerplate to the very minimum, leaving you to concentrate on the more interesting stuff."},{"talkType":"Conference","track":"Scala University","audienceLevel":"Débutant","summaryAsHtml":"<p>Scala, by being both Functional and Object-Oriented is easy to get started\nwith, especially for java developpers. However, to get the most of the\nlanguage, you have to embrace its functional nature.</p>\n<p>In this session, I&#x27;ll show you how to start using scala&#x27;s functional nature by\npresenting patterns originated in the functional world:</p>\n<ul>\n<li>Substitution model and &quot;everything is an expression&quot;</li>\n<li>Algebraic Data Types for data modelling</li>\n<li>Typeclasses for extensible abstractions</li>\n<li>Error handling in a composable fashion with Either and Validation</li>\n<li>Segregation between logic and effects for easier testing</li>\n<li>Property based testing</li>\n</ul>\n","id":"DDU-7873","speakers":[{"name":"Clément Delafargue","company":"Clever Cloud","id":"ad36032dfb473504555950435795ac48292b8a09","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/ad36032dfb473504555950435795ac48292b8a09","rel":"http://cfp.scala.io/api/profile/speaker","title":"Clément Delafargue"},"twitter":"@clementd"}],"title":"Functional patterns for scala practitionners","lang":"en","summary":"Scala, by being both Functional and Object-Oriented is easy to get started\r\nwith, especially for java developpers. However, to get the most of the\r\nlanguage, you have to embrace its functional nature.\r\n\r\n\r\nIn this session, I'll show you how to start using scala's functional nature by\r\npresenting patterns originated in the functional world:\r\n\r\n - Substitution model and \"everything is an expression\"\r\n - Algebraic Data Types for data modelling \r\n - Typeclasses for extensible abstractions\r\n - Error handling in a composable fashion with Either and Validation\r\n - Segregation between logic and effects for easier testing\r\n - Property based testing\r\n"},{"talkType":"Hands-on Labs","track":"Scala University","audienceLevel":"Débutant","summaryAsHtml":"<p>Si mon talk &quot;TDD, comm dans Type-Directed Development&quot; vous a convaincu, c&#x27;est le moment de mettre tout ça en pratique. Cet atelier vous permettra de développer une API et la logique métier associée pas à pas, avec le compilateur comme assistant.</p>\n<p>Seront abordés :</p>\n<ul>\n<li>Domain Driven Design avec case classes et enums</li>\n<li>Option pour dénoter les valeurs possiblement manquantes</li>\n<li>Écriture de code pas à pas, avec assistance du compilateur</li>\n<li>Tagged types pour s&#x27;assurer des étapes de traitement</li>\n</ul>\n","id":"BYC-3899","speakers":[{"name":"Clément Delafargue","company":"Clever Cloud","id":"ad36032dfb473504555950435795ac48292b8a09","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/ad36032dfb473504555950435795ac48292b8a09","rel":"http://cfp.scala.io/api/profile/speaker","title":"Clément Delafargue"},"twitter":"@clementd"},{"name":"Alexandre Berthaud","company":"Clever Cloud","id":"431097fd65a4f89ed73fd6c1f948ed8f3762612f","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/431097fd65a4f89ed73fd6c1f948ed8f3762612f","rel":"http://cfp.scala.io/api/profile/speaker","title":"Alexandre Berthaud"},"twitter":"@urcadox"}],"title":"TDD, comme dans Type-Directed Development","lang":"fr","summary":"Si mon talk \"TDD, comm dans Type-Directed Development\" vous a convaincu, c'est le moment de mettre tout ça en pratique. Cet atelier vous permettra de développer une API et la logique métier associée pas à pas, avec le compilateur comme assistant.\r\n\r\nSeront abordés :\r\n\r\n - Domain Driven Design avec case classes et enums\r\n - Option pour dénoter les valeurs possiblement manquantes\r\n - Écriture de code pas à pas, avec assistance du compilateur\r\n - Tagged types pour s'assurer des étapes de traitement\r\n"},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>Troy is an open source macro-based Cassandra driver, similar to Slick and Quill, provides type-safe &amp; compile-time checking for database queries. Nevertheless, it doesn&#x27;t impose a DSL to express the queries in Scala. Instead, it allows developers to write plain Cassandra-query-language (CQL) queries within Scala code, complete with schema validation. In addition, it provides cross-validation against the previous versions, ensuring safe and smooth schema migrations.</p>\n<p>It is worth noting that Troy doesn&#x27;t connect to Cassandra during compilation. Instead, the schema is provided as CQL scripts, checked-in within same code base, consisting of plain <code>CREATE TABLE</code> CQL statements. That get&#x27;s loaded at compile-time into a light-weight Schema engine capable of analysing queries and providing information about column types.\nThose CQL scripts can be written as increments, by adding new scripts containing <code>ALTER TABLE</code> statement, instead of editing existing scripts. This allows Troy to check compatibility of queries against different versions of the schema.</p>\n<p>Currently, Troy uses reflection-based black-box macros. But also has a working proof-of-concept using the new style inline/meta as well.</p>\n","id":"ITH-7524","speakers":[{"name":"Tamer AbdulRadi","company":"Cake Solutions Ltd","id":"4dbaab16f39c97caf0ad9fe3fdbbf8bfa72126d1","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/4dbaab16f39c97caf0ad9fe3fdbbf8bfa72126d1","rel":"http://cfp.scala.io/api/profile/speaker","title":"Tamer AbdulRadi"},"twitter":"@tabdulradi"}],"title":"Introducing Troy: The schema-safe Cassandra toolkit","lang":"en","summary":"Troy is an open source macro-based Cassandra driver, similar to Slick and Quill, provides type-safe & compile-time checking for database queries. Nevertheless, it doesn't impose a DSL to express the queries in Scala. Instead, it allows developers to write plain Cassandra-query-language (CQL) queries within Scala code, complete with schema validation. In addition, it provides cross-validation against the previous versions, ensuring safe and smooth schema migrations.\r\n\r\nIt is worth noting that Troy doesn't connect to Cassandra during compilation. Instead, the schema is provided as CQL scripts, checked-in within same code base, consisting of plain `CREATE TABLE` CQL statements. That get's loaded at compile-time into a light-weight Schema engine capable of analysing queries and providing information about column types.\r\nThose CQL scripts can be written as increments, by adding new scripts containing `ALTER TABLE` statement, instead of editing existing scripts. This allows Troy to check compatibility of queries against different versions of the schema.\r\n\r\nCurrently, Troy uses reflection-based black-box macros. But also has a working proof-of-concept using the new style inline/meta as well."},{"talkType":"Hands-on Labs","track":"BigData & MachineLearning","audienceLevel":"Débutant","summaryAsHtml":"<p>The workshop will show how to get started with Apache Spark and Spark Notebook to perform data analysis using Spark DataFrames and core Spark Notebook capabilities, perform feature extraction transformation and selection, build machine learning pipelines with Spark ML high-level APIs. The workshop is based on my machine learning labs on Apache Spark and Spark Notebook https://github.com/drewnoff/spark-notebook-ml-labs</p>\n<p>Prerequisites:\nSome experience coding in Scala, a basic understanding of data science topics and terminology, and some experience using Spark. Knowledge of RDDs and RDD transformations is assumed. No prior DataFrame or ML knowledge is required.</p>\n<p>Covered topics:\nSpark Notebook installation, Spark DataFrames, feature extraction and transformation, supervised learning and model evaluation, ML Pipelines.</p>\n","id":"MFT-5837","speakers":[{"name":"Andrey Romanov","company":"Yandex","id":"d7f9a35a48e87d7c53bfa9c97a9242a95d8301d2","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/d7f9a35a48e87d7c53bfa9c97a9242a95d8301d2","rel":"http://cfp.scala.io/api/profile/speaker","title":"Andrey Romanov"},"twitter":"@izhmyh"}],"title":"Data Science with Apache Spark and Spark Notebook","lang":"en","summary":"The workshop will show how to get started with Apache Spark and Spark Notebook to perform data analysis using Spark DataFrames and core Spark Notebook capabilities, perform feature extraction transformation and selection, build machine learning pipelines with Spark ML high-level APIs. The workshop is based on my machine learning labs on Apache Spark and Spark Notebook https://github.com/drewnoff/spark-notebook-ml-labs\r\n\r\nPrerequisites:\r\nSome experience coding in Scala, a basic understanding of data science topics and terminology, and some experience using Spark. Knowledge of RDDs and RDD transformations is assumed. No prior DataFrame or ML knowledge is required.\r\n\r\nCovered topics:\r\nSpark Notebook installation, Spark DataFrames, feature extraction and transformation, supervised learning and model evaluation, ML Pipelines."},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>Scala is particularly suited for creating DSLs. A great example would be a DSL\nfor acceptance/black-box testing of your product. Depending on the complexity\nof the input and output boundaries of your system, shifting more tests into\nthe black-box direction can yield numerous benefits.</p>\n<p>You can trade some unit-tests for acceptance tests that are still concise and\neasy to setup. This can particularly make sense if you are leveraging the\nexpressiveness of Scala&#x27;s type system. Of course you&#x27;ll still have a lot of\nunit-tests for units that are complex, e.g. have a lot of possible interactions\nor branching of execution paths. But having less unit-tests and more\nacceptance-level tests enables easier refactoring without losing much safety.</p>\n<p>Acceptance tests using custom DSLs also:</p>\n<ul>\n<li>act as great documentation operating directly on your domain concepts</li>\n<li>provide simpler abstraction of your system that is great for getting new developers up-to-speed</li>\n<li>can be used directly when splitting out parts of system or even going for a full rewrite</li>\n</ul>\n<p>In this talk we&#x27;ll explore tradeoffs inherit in using acceptance tests and see\nexamples of such testing DSLs.</p>\n","id":"QSN-4031","speakers":[{"name":"Ivan Kusalic","company":"HERE","id":"e762aab279ef2fc18180e81b71270fd26b57dd3a","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/e762aab279ef2fc18180e81b71270fd26b57dd3a","rel":"http://cfp.scala.io/api/profile/speaker","title":"Ivan Kusalic"},"twitter":"@ikusalic"}],"title":"Black-box testing with custom testkits","lang":"en","summary":"Scala is particularly suited for creating DSLs. A great example would be a DSL\r\nfor acceptance/black-box testing of your product. Depending on the complexity\r\nof the input and output boundaries of your system, shifting more tests into\r\nthe black-box direction can yield numerous benefits.\r\n\r\nYou can trade some unit-tests for acceptance tests that are still concise and\r\neasy to setup. This can particularly make sense if you are leveraging the\r\nexpressiveness of Scala's type system. Of course you'll still have a lot of\r\nunit-tests for units that are complex, e.g. have a lot of possible interactions\r\nor branching of execution paths. But having less unit-tests and more\r\nacceptance-level tests enables easier refactoring without losing much safety.\r\n\r\nAcceptance tests using custom DSLs also:\r\n\r\n* act as great documentation operating directly on your domain concepts\r\n* provide simpler abstraction of your system that is great for getting new developers up-to-speed\r\n* can be used directly when splitting out parts of system or even going for a full rewrite\r\n\r\nIn this talk we'll explore tradeoffs inherit in using acceptance tests and see\r\nexamples of such testing DSLs."},{"talkType":"Short conference","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>Le monitoring est un élément essentiel à la robustesse du parc applicatif. La métrologie permet aux équipes de développement, système et même parfois métier de surveiller efficacement la vie des applications.</p>\n<p>A travers un retour d&#x27;expérience sur la mise en place de la métrologie chez Brainify, je vous propose de découvrir ce domaine en essayant de répondre aux questions suivantes :</p>\n<p>Pourquoi a-t-on besoin de la métrologie ? Comment la mettre en oeuvre simplement à l&#x27;aide d&#x27;outils open-source comme Kamon, Statsd, Graphite, Grafana, ... ? Comment s&#x27;assurer de l&#x27;utilité et du suivi des métriques ? Comment l&#x27;utiliser pour être alerté et pour aider à la résolution d&#x27;incidents ?</p>\n","id":"AGI-6772","speakers":[{"name":"Matthieu Guillermin","company":"Brainify","id":"0a5942dee4c57081eec5b231e4b9ba7e567124f8","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/0a5942dee4c57081eec5b231e4b9ba7e567124f8","rel":"http://cfp.scala.io/api/profile/speaker","title":"Matthieu Guillermin"},"twitter":"@mguillermin"}],"title":"Utiliser la métrologie pour le monitoring des applications Scala","lang":"fr","summary":"Le monitoring est un élément essentiel à la robustesse du parc applicatif. La métrologie permet aux équipes de développement, système et même parfois métier de surveiller efficacement la vie des applications.\r\n\r\nA travers un retour d'expérience sur la mise en place de la métrologie chez Brainify, je vous propose de découvrir ce domaine en essayant de répondre aux questions suivantes :\r\n\r\nPourquoi a-t-on besoin de la métrologie ? Comment la mettre en oeuvre simplement à l'aide d'outils open-source comme Kamon, Statsd, Graphite, Grafana, ... ? Comment s'assurer de l'utilité et du suivi des métriques ? Comment l'utiliser pour être alerté et pour aider à la résolution d'incidents ?"},{"talkType":"Conference","track":"BigData & MachineLearning","audienceLevel":"Débutant","summaryAsHtml":"<p>Apache Spark est un framework permettant l&#x27;analyse de gros volumes de données permettant de mettre en place des pipelines complexes alliant récupération, traitement, apprentissage et visualisation des données (Notebook).</p>\n<p>Aprés une rapide introduction nous aborderons les points clés de Spark permettant de construire ce type de pipelines (Streaming, MLlib...).</p>\n<p>Ces fonctionnalités seront illustrées par des exemples concrets de code issus de deux projets sur lesquels je travaille actuellement:</p>\n<ol>\n<li><p>Moteur de recherche contextuelle sur les appels d&#x27;offres publics</p>\n<p>Pipeline combinant des fonctionnalités d&#x27;ETL pour la récupération et la mise en forme de données, la déduplication et l&#x27;extraction de features sur un gros dataset d&#x27;appels d&#x27;offres publics.</p>\n</li>\n<li><p>Analyse financière et prédiction des cotations de grands vins de Bordeaux</p>\n<p>Présentation d&#x27;un notebook d&#x27;exploration et d&#x27;analyse de données financières, comment acquérir une intuition permettant de comprendre les données analysées et déployer ensuite ces analyses en production pour prédire l&#x27;évolution des cotations de grands vins de Bordeaux.</p>\n</li>\n</ol>\n","id":"WLX-6379","speakers":[{"name":"Vincent Van Steenbergen","company":"Millesime.ai","id":"ba311cf8958cd55e560e104b4d6978a4a6dce4e3","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/ba311cf8958cd55e560e104b4d6978a4a6dce4e3","rel":"http://cfp.scala.io/api/profile/speaker","title":"Vincent Van Steenbergen"},"twitter":"@nsteenv"}],"title":"Retour d'expérience: pipeline de machine learning fonctionnelle avec Spark ","lang":"fr","summary":"Apache Spark est un framework permettant l'analyse de gros volumes de données permettant de mettre en place des pipelines complexes alliant récupération, traitement, apprentissage et visualisation des données (Notebook).\r\n\r\nAprés une rapide introduction nous aborderons les points clés de Spark permettant de construire ce type de pipelines (Streaming, MLlib...).\r\n\r\nCes fonctionnalités seront illustrées par des exemples concrets de code issus de deux projets sur lesquels je travaille actuellement:\r\n\r\n1. Moteur de recherche contextuelle sur les appels d'offres publics\r\n\r\n    Pipeline combinant des fonctionnalités d'ETL pour la récupération et la mise en forme de données, la déduplication et l'extraction de features sur un gros dataset d'appels d'offres publics.\r\n\r\n2. Analyse financière et prédiction des cotations de grands vins de Bordeaux\r\n\r\n    Présentation d'un notebook d'exploration et d'analyse de données financières, comment acquérir une intuition permettant de comprendre les données analysées et déployer ensuite ces analyses en production pour prédire l'évolution des cotations de grands vins de Bordeaux."},{"talkType":"Short conference","track":"Scala & Ecosystem","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>Avec plus de 100k events / secondes, tabmo implémente un unified log sur la base de apache kafka.</p>\n<p>Sur l’infrastructure d’Amazon, des clients c++ et scala échangent messages et événements par le biais de kafka, donc de manière asynchrone et même très récemment à la sauce “réactive” grâce à akka stream.</p>\n<p>Ces flux, plus ou moins remaniés peuvent être ingérés par des outils de visualisation tel que <a href=\"http://druid.io\">Druid</a>, une solution de cube “big data”.</p>\n<p>Le modèle de flow / graph d’akka stream peut s’appliquer parfaitement et très simplement à l’ensemble de ces étapes:</p>\n<ul>\n<li>Sources et Sinks réactives (pour kafka et druid).</li>\n<li>des combinateurs (split, merge, filters) pour router, trier, filtrer les messages.</li>\n<li>simple lambda pour les traitements.</li>\n</ul>\n<p>Il est assez facile de créer ses propres composants, ce que nous illustrerons avec un Sink qui publie dans une datasource druid en quelques lignes de code.</p>\n","id":"UNR-2028","speakers":[{"name":"Olivier NOUGUIER","company":"TabMo","id":"b781fe404324b0c1d7d67a82b0cfca87cd67a473","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/b781fe404324b0c1d7d67a82b0cfca87cd67a473","rel":"http://cfp.scala.io/api/profile/speaker","title":"Olivier NOUGUIER"},"twitter":"@oNouguier"}],"title":"Akka Stream from Kafka to Druid","lang":"fr","summary":"Avec plus de 100k events / secondes, tabmo implémente un unified log sur la base de apache kafka.\r\n\r\nSur l’infrastructure d’Amazon, des clients c++ et scala échangent messages et événements par le biais de kafka, donc de manière asynchrone et même très récemment à la sauce “réactive” grâce à akka stream.\r\n\r\nCes flux, plus ou moins remaniés peuvent être ingérés par des outils de visualisation tel que [Druid](http://druid.io), une solution de cube “big data”.\r\n\r\nLe modèle de flow / graph d’akka stream peut s’appliquer parfaitement et très simplement à l’ensemble de ces étapes: \r\n\r\n* Sources et Sinks réactives (pour kafka et druid).\r\n* des combinateurs (split, merge, filters) pour router, trier, filtrer les messages.\r\n* simple lambda pour les traitements. \r\n\r\nIl est assez facile de créer ses propres composants, ce que nous illustrerons avec un Sink qui publie dans une datasource druid en quelques lignes de code. "},{"talkType":"Hands-on Labs","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>Talk is cheap - show me the code! Get hands on with Lagom and Scala in this 3h workshop.\nDuring which, we will use Scala to build a system based on Lagom microservices. We will persist data using Event Sourcing / CQRS, and introduce common patterns in microservice development, such as the circuit breaker. We will explore the aspects of scalability and resilience in our system, including pitfalls. At the end of this workshop participants should have a good understanding of how to build a system based on Lagom, and of some common concepts in microservice development.</p>\n<p>Participants are required to bring their own computer with a working Scala development environment (JDK, sbt, IDE/Editor of choice).</p>\n","id":"MGJ-9341","speakers":[{"name":"Lutz Huehnken","company":"Lightbend, Inc.","id":"cbfa1e53653d8b23699a9b62f012b5687a1cf1b4","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/cbfa1e53653d8b23699a9b62f012b5687a1cf1b4","rel":"http://cfp.scala.io/api/profile/speaker","title":"Lutz Huehnken"},"twitter":"@lutzhuehnken"}],"title":"Lagom Microservice Workshop","lang":"en","summary":"Talk is cheap - show me the code! Get hands on with Lagom and Scala in this 3h workshop. \r\nDuring which, we will use Scala to build a system based on Lagom microservices. We will persist data using Event Sourcing / CQRS, and introduce common patterns in microservice development, such as the circuit breaker. We will explore the aspects of scalability and resilience in our system, including pitfalls. At the end of this workshop participants should have a good understanding of how to build a system based on Lagom, and of some common concepts in microservice development.\r\n\r\nParticipants are required to bring their own computer with a working Scala development environment (JDK, sbt, IDE/Editor of choice)."},{"talkType":"Short conference","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p><a href=\"https://github.com/tpolecat/doobie\"><strong>Doobie</strong></a> se présente par l&#x27;accroche <em>principled database access for an unprincipled world</em>. C&#x27;est tout à fait intraduisible en français - et c&#x27;est bien dommage ! Car cette phrase résume tout l&#x27;esprit de cette surcouche de <em>JDBC</em>.</p>\n<p>Grâce à <strong>Doobie</strong>, <em>JDBC</em>, l&#x27;incarnation de Java à la mode &#x27;90s, des variables globales mutables qui jouent avec des threads, devient une bibliothèque fonctionnelle de pures structures de données composables, échangeables, testables, raisonnables - et tout ceci avec du <em>SQL</em>.\nCar là où d&#x27;autres comme <em>Slick</em> ont choisi la voie du mapping objets / base de données, non sans rappeler nos bons vieux ORM honnis, <strong>Doobie</strong> ne fait que rendre vos requêtes <em>SQL</em> de bonnes citoyennes d&#x27;applications fonctionnelles.</p>\n<p>Utilisateur récent de <strong>Doobie</strong>, je me propose dans cette présentation de vous transmettre un retour d&#x27;expérience encore chaud et naïf, avec ses bonnes surprises, ses moins bonnes, et pourquoi pas un mot sur Slick 3.1.</p>\n","id":"VYK-8530","speakers":[{"name":"François Armand","company":"Normation","id":"2a3086b146192258297b5744fb69b61676546a3e","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/2a3086b146192258297b5744fb69b61676546a3e","rel":"http://cfp.scala.io/api/profile/speaker","title":"François Armand"},"twitter":"@fanf42"}],"title":"Rex \"Doobie\": Un JDBC fonctionnel qui ne cache pas SQL","lang":"fr","summary":"[**Doobie**](https://github.com/tpolecat/doobie) se présente par l'accroche *principled database access for an unprincipled world*. C'est tout à fait intraduisible en français - et c'est bien dommage ! Car cette phrase résume tout l'esprit de cette surcouche de *JDBC*. \r\n\r\nGrâce à **Doobie**, *JDBC*, l'incarnation de Java à la mode '90s, des variables globales mutables qui jouent avec des threads, devient une bibliothèque fonctionnelle de pures structures de données composables, échangeables, testables, raisonnables - et tout ceci avec du *SQL*. \r\nCar là où d'autres comme *Slick* ont choisi la voie du mapping objets / base de données, non sans rappeler nos bons vieux ORM honnis, **Doobie** ne fait que rendre vos requêtes *SQL* de bonnes citoyennes d'applications fonctionnelles. \r\n\r\nUtilisateur récent de **Doobie**, je me propose dans cette présentation de vous transmettre un retour d'expérience encore chaud et naïf, avec ses bonnes surprises, ses moins bonnes, et pourquoi pas un mot sur Slick 3.1. "},{"talkType":"Quickie","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>Most high-level Javascript libraries for plotting have well designed APIs, enforcing immutability and almost relying on typed objects, although not explicitly. Yet, the few existing Scala libraries for plotting still have APIs requiring users to mutate things in order to do plots, mimicking matplotlib or Matlab. They also lack lots of features compared to high-end Javascript plotting libraries. <a href=\"https://github.com/alexarchambault/plotly-scala\">plotly-scala</a> aims at addressing this, by providing a reliable bridge from Scala towards the renowned plotly.js. It does so by automatically validating whole sections of the plotly.js documentation, thereby ensuring that it can handle all of their features.</p>\n","id":"WUL-8641","speakers":[{"name":"Alexandre Archambault","company":"Teads.tv","id":"27c838e9e14140ca9921626104ea52f9d4f910f2","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/27c838e9e14140ca9921626104ea52f9d4f910f2","rel":"http://cfp.scala.io/api/profile/speaker","title":"Alexandre Archambault"},"twitter":"@alxarchambault"}],"title":"plotly-scala - having Scala catch up on Javascript plotting libraries!","lang":"en","summary":"Most high-level Javascript libraries for plotting have well designed APIs, enforcing immutability and almost relying on typed objects, although not explicitly. Yet, the few existing Scala libraries for plotting still have APIs requiring users to mutate things in order to do plots, mimicking matplotlib or Matlab. They also lack lots of features compared to high-end Javascript plotting libraries. [plotly-scala](https://github.com/alexarchambault/plotly-scala) aims at addressing this, by providing a reliable bridge from Scala towards the renowned plotly.js. It does so by automatically validating whole sections of the plotly.js documentation, thereby ensuring that it can handle all of their features."},{"talkType":"Conference","track":"Type & Functional Programming","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>In this talk we&#x27;ll learn about what an algebra is, why functional programmers talk about them constantly, and how you can use them in your projects. Algebras <em>are</em> structure, and we&#x27;ll talk about their various forms: algebraic data types, F-algebras, object algebras, and more!</p>\n","id":"LSP-1078","speakers":[{"name":"Adam Rosien","company":"Underscore","id":"78a153f1dfd4c6aaace1b49a5069ee82863d35fa","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/78a153f1dfd4c6aaace1b49a5069ee82863d35fa","rel":"http://cfp.scala.io/api/profile/speaker","title":"Adam Rosien"},"twitter":"@arosien"}],"title":"Why do functional programmers always talk about algebra(s)?","lang":"en","summary":"In this talk we'll learn about what an algebra is, why functional programmers talk about them constantly, and how you can use them in your projects. Algebras *are* structure, and we'll talk about their various forms: algebraic data types, F-algebras, object algebras, and more!"},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>This talk explains a dependency injection technique that checks asynchronous dependencies in compile time. You will learn how to use functional, type-driven dependencies definitions and type safe injection.</p>\n<p>In actor model, an actor often has to initialise its state using asynchronous dependencies - like messages from other actors or Futures. Collecting such dependencies inside the actor introduces some boilerplate and code duplication. Moreover, composing asynchronous invocations requires extra focus to be implemented correctly and efficiently. We can free actors from this overhead and let programmers define reusable asynchronous dependencies easily. If you are used to resolving your dependency problems using runtime error messages, compile time dependency injection will be an eye-opening experience.</p>\n<p>I will present the design and API of a simple DI library and explain its type-driven nature. Correctness and fulfilment of injected dependencies is checked in compile time. Likewise, the compiler takes care of composing asynchronous invocations efficiently due to full types awareness. I will explain how Scala and Shapeless allow us to achieve this level of type safety.</p>\n","id":"IXI-8110","speakers":[{"name":"Grzegorz Wilaszek","company":"Ocado Technology","id":"7caba419ca9c37101eeb965b8adb2bb8c06a0c87","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/7caba419ca9c37101eeb965b8adb2bb8c06a0c87","rel":"http://cfp.scala.io/api/profile/speaker","title":"Grzegorz Wilaszek"},"twitter":"@wilaszekg"}],"title":"Type safe dependency injection in reactive applications","lang":"en","summary":"This talk explains a dependency injection technique that checks asynchronous dependencies in compile time. You will learn how to use functional, type-driven dependencies definitions and type safe injection.\r\n\r\nIn actor model, an actor often has to initialise its state using asynchronous dependencies - like messages from other actors or Futures. Collecting such dependencies inside the actor introduces some boilerplate and code duplication. Moreover, composing asynchronous invocations requires extra focus to be implemented correctly and efficiently. We can free actors from this overhead and let programmers define reusable asynchronous dependencies easily. If you are used to resolving your dependency problems using runtime error messages, compile time dependency injection will be an eye-opening experience.\r\n\r\nI will present the design and API of a simple DI library and explain its type-driven nature. Correctness and fulfilment of injected dependencies is checked in compile time. Likewise, the compiler takes care of composing asynchronous invocations efficiently due to full types awareness. I will explain how Scala and Shapeless allow us to achieve this level of type safety."},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>Last spring the geek in me got tempted to grab 5 battery- and wireless valve regulators for our appartements radiators. I had already checked that I should be able to communicate with these using a Raspberry Pi module, but the details of how to get this up and running was still uncertain as winter approcached and the tempearture in the appartement slowely started to descend. This is the story of creating a quite usefull functional reactive application with Scala and Akka and interacting with Raspberry Pi&#x27;s serial port.</p>\n","id":"GQM-2374","speakers":[{"name":"Trond Bjerkestrand","company":"Groosker","id":"18445d8c5cd26ab5e2656763bfb0d5f950d50ae4","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/18445d8c5cd26ab5e2656763bfb0d5f950d50ae4","rel":"http://cfp.scala.io/api/profile/speaker","title":"Trond Bjerkestrand"},"twitter":"@tbjerkes"}],"title":"Temperature control with Raspberry Pi and Akka.","lang":"en","summary":"Last spring the geek in me got tempted to grab 5 battery- and wireless valve regulators for our appartements radiators. I had already checked that I should be able to communicate with these using a Raspberry Pi module, but the details of how to get this up and running was still uncertain as winter approcached and the tempearture in the appartement slowely started to descend. This is the story of creating a quite usefull functional reactive application with Scala and Akka and interacting with Raspberry Pi's serial port."},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>Apache Spark is a cluster computing framework. Shapeless is a generic programming library for Scala. In this talk, we will look at how Shapeless can be used to mirror value-level computation to the type-level, and to provide more typeful experience working with Spark.</p>\n<p>The presentation comes in two parts. First, we present the evolution of Spark&#x27;s APIs, explain what motivated these changes, and highlight the limitations we encountered while working with Spark. Second, we give an introduction to Frameless, a library based on Shapeless developed to work around these limitations. In particular, we show how implicit resolution can replace Java reflection to derive Encoders for case classes.</p>\n<p>This talk targets Scala developers with no prior Spark or Shapeless experience.</p>\n","id":"XRG-8187","speakers":[{"name":"Olivier Blanvillain","company":"MFG Labs","id":"c13dde73754b8df56a92163e7c4c5af5a207556a","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/c13dde73754b8df56a92163e7c4c5af5a207556a","rel":"http://cfp.scala.io/api/profile/speaker","title":"Olivier Blanvillain"},"twitter":null},{"name":"Amine Benhalloum","company":"MFG Labs","id":"100851f581b8abaf78a0dcaf527ac355b7733f7d","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/100851f581b8abaf78a0dcaf527ac355b7733f7d","rel":"http://cfp.scala.io/api/profile/speaker","title":"Amine Benhalloum"},"twitter":null}],"title":"Typesafe DataFrame with Spark and Shapeless","lang":"fr","summary":"Apache Spark is a cluster computing framework. Shapeless is a generic programming library for Scala. In this talk, we will look at how Shapeless can be used to mirror value-level computation to the type-level, and to provide more typeful experience working with Spark.\r\n\r\nThe presentation comes in two parts. First, we present the evolution of Spark's APIs, explain what motivated these changes, and highlight the limitations we encountered while working with Spark. Second, we give an introduction to Frameless, a library based on Shapeless developed to work around these limitations. In particular, we show how implicit resolution can replace Java reflection to derive Encoders for case classes.\r\n\r\nThis talk targets Scala developers with no prior Spark or Shapeless experience."},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>Dans un langage de programmation fonctionnel comme Scala, nous voulons isoler les effets du reste du code de nos applications. Pour ce faire, nous utilisons évidemment le type system. Cette séparation nous permet de construire des applications plus robustes, mais ne nous met pour autant pas à l’abri de problèmes en production. Il faut impérativement observer l&#x27;exécution de nos programmes pour s’assurer de leur bon fonctionnement.</p>\n<p>Dans ce talk, nous verrons comment Précepte nous permet à la fois de représenter les effets dans le type system, mais aussi de fournir du contexte au compile time que nous utilisons pour monitorer facilement et précisément le runtime.</p>\n","id":"KGU-1120","speakers":[{"name":"Julien Tournay","company":"MFG Labs","id":"182f268bed57d819b156b952abbb72ff1e0b1c8f","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/182f268bed57d819b156b952abbb72ff1e0b1c8f","rel":"http://cfp.scala.io/api/profile/speaker","title":"Julien Tournay"},"twitter":"@skaalf"}],"title":"Contextualiser au compile time pour observer au runtime avec Précepte.","lang":"fr","summary":"Dans un langage de programmation fonctionnel comme Scala, nous voulons isoler les effets du reste du code de nos applications. Pour ce faire, nous utilisons évidemment le type system. Cette séparation nous permet de construire des applications plus robustes, mais ne nous met pour autant pas à l’abri de problèmes en production. Il faut impérativement observer l'exécution de nos programmes pour s’assurer de leur bon fonctionnement.\r\n\r\nDans ce talk, nous verrons comment Précepte nous permet à la fois de représenter les effets dans le type system, mais aussi de fournir du contexte au compile time que nous utilisons pour monitorer facilement et précisément le runtime."},{"talkType":"Hands-on Labs","track":"Type & Functional Programming","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>Typeclasses have often frightening names such as Functor, Monoid or Applicative, but they are in fact a very simple and elegant concept. A typeclass is a way to apply a function to different types or, in other words, it permits polymorphism. In that sense, Typeclasses are similar to inheritance in object-oriented languages, yet typeclasses are both more powerful and safer to reason with thanks to invariants/laws.</p>\n<p>The objective of this workshop is to provide a solid understanding of typeclasses and illustrate how they can be used and implemented in scala. The workshop will consist of many exercises available on github.</p>\n","id":"VNR-0442","speakers":[{"name":"Julien Truffaut","company":"Freelance","id":"e6b020fdb4cf4b6c35b6c2e3f7bb96cd2d5ccfaf","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/e6b020fdb4cf4b6c35b6c2e3f7bb96cd2d5ccfaf","rel":"http://cfp.scala.io/api/profile/speaker","title":"Julien Truffaut"},"twitter":"@JulienTruffaut"}],"title":"Typeclass 101: ad hoc polymorphism in scala","lang":"en","summary":"Typeclasses have often frightening names such as Functor, Monoid or Applicative, but they are in fact a very simple and elegant concept. A typeclass is a way to apply a function to different types or, in other words, it permits polymorphism. In that sense, Typeclasses are similar to inheritance in object-oriented languages, yet typeclasses are both more powerful and safer to reason with thanks to invariants/laws.\r\n\r\nThe objective of this workshop is to provide a solid understanding of typeclasses and illustrate how they can be used and implemented in scala. The workshop will consist of many exercises available on github."},{"talkType":"Conference","track":"Scala University","audienceLevel":"Débutant","summaryAsHtml":"<p>Pour les applications qui, comme beaucoup, doivent communiquer intensément avec des services distants, les API de traitement asynchrones sont un atout majeur du langage Scala. Venez découvrir comment jongler avec les <code>Future</code>, les enchainer, les regrouper, le tout en consommant un minimum de resources et toujours <strong>type safe</strong> !</p>\n","id":"KTG-4597","speakers":[{"name":"Brice LEPORINI","company":"Freelance","id":"108a8a63f261caa8a0f55470bdb5cca65c7abdf8","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/108a8a63f261caa8a0f55470bdb5cca65c7abdf8","rel":"http://cfp.scala.io/api/profile/speaker","title":"Brice LEPORINI"},"twitter":"@blep"}],"title":"Future composé","lang":"fr","summary":"Pour les applications qui, comme beaucoup, doivent communiquer intensément avec des services distants, les API de traitement asynchrones sont un atout majeur du langage Scala. Venez découvrir comment jongler avec les `Future`, les enchainer, les regrouper, le tout en consommant un minimum de resources et toujours **type safe** !\r\n\r\n  "},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>In July 2015 Facebook released the first draft of GraphQL specification. <a href=\"http://graphql.org\">GraphQL</a> provides an alternative to the REST API with a high emphasis on efficient data retrieval and introspection with a powerful type system behind it. It allows you to build the client applications based on highly decoupled components without sacrificing performance or over-/under-fetching a data. GraphQL is ideal for any application that requires very precise and performant data fetching/manipulation, like mobile applications. GraphQL type system is not only a perfect fit for scala applications, but it also opens a door for a brand new set of tools for API discovery, documentation, and code generation. In this talk I would like to give an introduction to GraphQL - the concepts behind it and how it addresses common API design challenges like versioning, documentation, and discovery. You will learn how you can start using GraphQL today in your scala applications with <a href=\"http://sangria-graphql.org\">Sangria</a> - the scala GraphQL implementation.</p>\n","id":"PLO-4469","speakers":[{"name":"Oleg Ilyenko","company":null,"id":"a30924b588a47c7bdce1b2ba60483308e9a58812","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/a30924b588a47c7bdce1b2ba60483308e9a58812","rel":"http://cfp.scala.io/api/profile/speaker","title":"Oleg Ilyenko"},"twitter":"@easyangel"}],"title":"GraphQL - a type system for your API","lang":"en","summary":"In July 2015 Facebook released the first draft of GraphQL specification. [GraphQL](http://graphql.org) provides an alternative to the REST API with a high emphasis on efficient data retrieval and introspection with a powerful type system behind it. It allows you to build the client applications based on highly decoupled components without sacrificing performance or over-/under-fetching a data. GraphQL is ideal for any application that requires very precise and performant data fetching/manipulation, like mobile applications. GraphQL type system is not only a perfect fit for scala applications, but it also opens a door for a brand new set of tools for API discovery, documentation, and code generation. In this talk I would like to give an introduction to GraphQL - the concepts behind it and how it addresses common API design challenges like versioning, documentation, and discovery. You will learn how you can start using GraphQL today in your scala applications with [Sangria](http://sangria-graphql.org) - the scala GraphQL implementation."},{"talkType":"Conference","track":"Scala University","audienceLevel":"Débutant","summaryAsHtml":"<p>The Scala language and its environment have been evolving quite\nsignificantly over the past few years. The adoption of the language is\nslowly growing and it can now even be found in use in rather conservative\nenterprise settings. At the same time there have been quite a few criticism\nof the language, its ecosystem and its practicability in larger teams. Many\ndevelopers are still avoiding to have a more serious look at Scala and its\necosystem for a variety of reasons ranging from the fear of good tooling\nsupport to the apprehension of advanced category theory principles.</p>\n<p>This talk is a reflection upon six years of working professionally with\nScala in projects of various size and shape. It aims at conveying some of\nthe learnings and practical insights gained during that time as well as to\ndebunk some of the many preconceptions that surround the language and its\necosystem.</p>\n","id":"RDT-9623","speakers":[{"name":"Manuel Bernhardt","company":"manuel.bernhardt.io","id":"ef4c9c3b4a7f7e7ca058103ce8a811ad06673f0e","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/ef4c9c3b4a7f7e7ca058103ce8a811ad06673f0e","rel":"http://cfp.scala.io/api/profile/speaker","title":"Manuel Bernhardt"},"twitter":"@elmanu"}],"title":"Six years of Scala and counting","lang":"en","summary":"The Scala language and its environment have been evolving quite\r\nsignificantly over the past few years. The adoption of the language is\r\nslowly growing and it can now even be found in use in rather conservative\r\nenterprise settings. At the same time there have been quite a few criticism\r\nof the language, its ecosystem and its practicability in larger teams. Many\r\ndevelopers are still avoiding to have a more serious look at Scala and its\r\necosystem for a variety of reasons ranging from the fear of good tooling\r\nsupport to the apprehension of advanced category theory principles.\r\n\r\nThis talk is a reflection upon six years of working professionally with\r\nScala in projects of various size and shape. It aims at conveying some of\r\nthe learnings and practical insights gained during that time as well as to\r\ndebunk some of the many preconceptions that surround the language and its\r\necosystem.\r\n"},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>Since its inception more than 2 years ago the effort for establishing a standard protocol for asynchronous stream processing under the name <em>Reactive Streams</em> (RS) has received a lot of attention. Many users and organizations are excited by this powerful new abstraction for defining and scaling pipelined processing logic in a fully asynchronous, non-blocking and generally reactive fashion.</p>\n<p>In order to further explore the design space of the still young Reactive Streams domain another fully-featured Reactive Streams infrastructure toolkit for Scala, called <em>swave</em>, has been built from scratch with a clear focus on max performance, a simple and powerful API as well as minimal dependencies.</p>\n<p>This talk will introduce you to the project, its general design approach, feature set and core implementation choices as well as basic benchmark and performance figures.\nWe&#x27;ll contrast with other RS implementations and highlight pros and cons from a user&#x27;s perspective.</p>\n<p>So the next time you are faced with the question of which Reactive Streams implementation to use you&#x27;ll have one more attractive choice to pick from.</p>\n","id":"QNK-6733","speakers":[{"name":"Mathias Doenitz","company":null,"id":"bb2d6d146113ed2081152bf2c6d123e920204793","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/bb2d6d146113ed2081152bf2c6d123e920204793","rel":"http://cfp.scala.io/api/profile/speaker","title":"Mathias Doenitz"},"twitter":"@sirthias"}],"title":"Swave - a fresh Reactive Streams Implementation","lang":"en","summary":"Since its inception more than 2 years ago the effort for establishing a standard protocol for asynchronous stream processing under the name *Reactive Streams* (RS) has received a lot of attention. Many users and organizations are excited by this powerful new abstraction for defining and scaling pipelined processing logic in a fully asynchronous, non-blocking and generally reactive fashion.\r\n\r\nIn order to further explore the design space of the still young Reactive Streams domain another fully-featured Reactive Streams infrastructure toolkit for Scala, called *swave*, has been built from scratch with a clear focus on max performance, a simple and powerful API as well as minimal dependencies.\r\n\r\nThis talk will introduce you to the project, its general design approach, feature set and core implementation choices as well as basic benchmark and performance figures.\r\nWe'll contrast with other RS implementations and highlight pros and cons from a user's perspective.\r\n\r\nSo the next time you are faced with the question of which Reactive Streams implementation to use you'll have one more attractive choice to pick from. "},{"talkType":"Short conference","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>Herbert est excité. Il vient de découvrir les architectures microservices à Devoxx 2015 et est immédiatement convaincu que ce modèle représente l&#x27;avenir des architectures web. De retour au travail, il se lance immédiatement dans le découpage de sa vieille application monolithique en un très moderne écosystème d&#x27;API, ou toutes les micro-applications RESTFUL communiquent entre elles en s&#x27;envoyant des messages JSON en HTTP. Mais très rapidement, Herbert se rend compte qu&#x27;il n&#x27;est pas si facile d&#x27;interconnecter toutes ces applications. Les requêtes internes se démultiplient, la latence augmente en flèche et la fiabilité du système est en chute libre. Herbert est pensif… peut-être que REST n&#x27;était pas le meilleur modèle au final ?</p>\n<p>Si vous vous reconnaissez dans cette petite histoire, alors cette présentation est faite pour vous !</p>\n<p>Dans ce talk nous verrons plusieurs alternatives à la solution REST/JSON qui permettent de répondre plus efficacement aux problématiques de fiabilité, latence, maintenabilité... via un retour d&#x27;expérience sur des modèles de communication alternatifs (remote actors, queue messaging, websocket server-side...) et différents moyens de définir vos protocoles.</p>\n","id":"XFF-8873","speakers":[{"name":"Julien Lafont","company":"Tabmo","id":"e42fad13977cb0f547ebd5a5553bb436b6e339a3","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/e42fad13977cb0f547ebd5a5553bb436b6e339a3","rel":"http://cfp.scala.io/api/profile/speaker","title":"Julien Lafont"},"twitter":"@julien_lafont"}],"title":"Architectures micro-services sans HTTP","lang":"fr","summary":"Herbert est excité. Il vient de découvrir les architectures microservices à Devoxx 2015 et est immédiatement convaincu que ce modèle représente l'avenir des architectures web. De retour au travail, il se lance immédiatement dans le découpage de sa vieille application monolithique en un très moderne écosystème d'API, ou toutes les micro-applications RESTFUL communiquent entre elles en s'envoyant des messages JSON en HTTP. Mais très rapidement, Herbert se rend compte qu'il n'est pas si facile d'interconnecter toutes ces applications. Les requêtes internes se démultiplient, la latence augmente en flèche et la fiabilité du système est en chute libre. Herbert est pensif… peut-être que REST n'était pas le meilleur modèle au final ?\r\n\r\nSi vous vous reconnaissez dans cette petite histoire, alors cette présentation est faite pour vous !\r\n\r\nDans ce talk nous verrons plusieurs alternatives à la solution REST/JSON qui permettent de répondre plus efficacement aux problématiques de fiabilité, latence, maintenabilité... via un retour d'expérience sur des modèles de communication alternatifs (remote actors, queue messaging, websocket server-side...) et différents moyens de définir vos protocoles."},{"talkType":"Short conference","track":"BigData & MachineLearning","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>Lorsque le volume et la complexité des données augmentent, la data-science, comme un enfant, se doit d’évoluer pour devenir plus mature.\nCe talk vous présentera comment les bibliothèques tels que <a href=\"https://saddle.github.io/\">Saddle</a>, <a href=\"http://haifengl.github.io/smile/\">Smile</a> et <a href=\"http://spark.apache.org/docs/latest/mllib-guide.html\">Spark Mllib</a> profitent de l’aspect fonctionnel de scala, de son hybridité avec la programmation orienté-objet et de ses prédispositions à la scalabilité pour répondre aux nouvelles exigences de data-science. Elle passe alors d’un rôle d’enfant-explorateur au rôle de scientifique aguerri pour faciliter et donner plus de pouvoir à la statistique descriptive et l’analyse en temps réel de Big Data.\nAvec en fil rouge une démo de machine learning sur la prédiction de clic sur des espaces publicitaires, nous explorerons les possibilités, les avantages et les pistes d&#x27;amélioration de Scala dans la data-science.</p>\n","id":"EQU-0401","speakers":[{"name":"Anastasia Lieva","company":" Tabmo","id":"c36e1107a63489bec66560e3b664ebdae44c29c7","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/c36e1107a63489bec66560e3b664ebdae44c29c7","rel":"http://cfp.scala.io/api/profile/speaker","title":"Anastasia Lieva"},"twitter":" @lievAnastazia"}],"title":"Big-Data-science en scala","lang":"fr","summary":"Lorsque le volume et la complexité des données augmentent, la data-science, comme un enfant, se doit d’évoluer pour devenir plus mature.\r\nCe talk vous présentera comment les bibliothèques tels que [Saddle](https://saddle.github.io/), [Smile](http://haifengl.github.io/smile/) et [Spark Mllib](http://spark.apache.org/docs/latest/mllib-guide.html) profitent de l’aspect fonctionnel de scala, de son hybridité avec la programmation orienté-objet et de ses prédispositions à la scalabilité pour répondre aux nouvelles exigences de data-science. Elle passe alors d’un rôle d’enfant-explorateur au rôle de scientifique aguerri pour faciliter et donner plus de pouvoir à la statistique descriptive et l’analyse en temps réel de Big Data. \r\nAvec en fil rouge une démo de machine learning sur la prédiction de clic sur des espaces publicitaires, nous explorerons les possibilités, les avantages et les pistes d'amélioration de Scala dans la data-science. \r\n"},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>Monad Transformers. &quot;WAT?&quot; &quot;Exactly&quot;</p>\n<p>In this session we&#x27;ll see what monad transformers are, where their need comes from and how to use them effectively</p>\n<p>We&#x27;ll walk through this rather complicated topic guided by real-life examples, with the noble intent of making our code more readable, maintainable and pleasant to work with.</p>\n<p>Finally we&#x27;ll see how Monad Transformers are just one of possible tools to solve the &quot;effect stacking&quot; and hint at other possible solutions.</p>\n<p>WARNING</p>\n<p>This talk contains slides that some viewers may find disturbing, most of them containing words like &quot;monad&quot; and/or &quot;functors&quot;</p>\n<p>Listener discretion advised</p>\n","id":"UUY-6087","speakers":[{"name":"Gabriele Petronella","company":"buildo","id":"9183e23a13d49b69f636024e250e1a45c27d80a5","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/9183e23a13d49b69f636024e250e1a45c27d80a5","rel":"http://cfp.scala.io/api/profile/speaker","title":"Gabriele Petronella"},"twitter":"@gabro27"}],"title":"Monad Transformers, what and why?","lang":"en","summary":"Monad Transformers. \"WAT?\" \"Exactly\"\r\n\r\nIn this session we'll see what monad transformers are, where their need comes from and how to use them effectively\r\n\r\nWe'll walk through this rather complicated topic guided by real-life examples, with the noble intent of making our code more readable, maintainable and pleasant to work with.\r\n\r\nFinally we'll see how Monad Transformers are just one of possible tools to solve the \"effect stacking\" and hint at other possible solutions.\r\n\r\nWARNING\r\n\r\nThis talk contains slides that some viewers may find disturbing, most of them containing words like \"monad\" and/or \"functors\"\r\n\r\nListener discretion advised"},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>The Typelevel fork of the Scala compiler has been reinvigorated by the recent community fix for SI-2712, a long-standing problem of type inference for projects which make extensive use of higher-kinded types.</p>\n<p>Thanks to newly arrived improvements in the compiler build process and SBT it is now dramatically easier to explore and work on compiler internals and use the results in existing Scala projects. Moreover the experience over the last year of activity and collaboration between other Typelevel projects means that we have a clearer idea of what new language features and compiler bug fixes are really of value to the community. The combination of these developments has lowered the barriers to participation in compiler development and provided focus.</p>\n<p>In this talk I will show what&#x27;s new in Typelevel Scala, explain how you can use it in your projects today, discuss the collaboration with the Scala team at Lightbend which is making this possible, and encourage you to get involved yourselves.</p>\n","id":"RLV-6539","speakers":[{"name":"Miles Sabin","company":"Underscore","id":"d45538c200cfe42a24369c12c33f6f7985ced9fb","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/d45538c200cfe42a24369c12c33f6f7985ced9fb","rel":"http://cfp.scala.io/api/profile/speaker","title":"Miles Sabin"},"twitter":"@milessabin"}],"title":"Typelevel Scala Rebooted","lang":"en","summary":"The Typelevel fork of the Scala compiler has been reinvigorated by the recent community fix for SI-2712, a long-standing problem of type inference for projects which make extensive use of higher-kinded types.\r\n\r\nThanks to newly arrived improvements in the compiler build process and SBT it is now dramatically easier to explore and work on compiler internals and use the results in existing Scala projects. Moreover the experience over the last year of activity and collaboration between other Typelevel projects means that we have a clearer idea of what new language features and compiler bug fixes are really of value to the community. The combination of these developments has lowered the barriers to participation in compiler development and provided focus.\r\n\r\nIn this talk I will show what's new in Typelevel Scala, explain how you can use it in your projects today, discuss the collaboration with the Scala team at Lightbend which is making this possible, and encourage you to get involved yourselves.\r\n"},{"talkType":"Short conference","track":"Scala University","audienceLevel":"Débutant","summaryAsHtml":"<p>ScalaCheck is a well-known library for property-base testing. However, property-base testing is not always possible when side effects are involved, for example when writing an integration test that involves data being stored in a database. When writing non-property-base tests, we often need to initialise some data and then verify some assertions on it. However, manual data generation can make our data biased and stop from spotting bugs in our code. Having our data generated randomly not only it would make our test less biased, but it will also make it a lot more readable by highlighting what part of our data are actually relevant in our test.</p>\n<p>In this talk we will discuss how to reuse some of the existing ScalaCheck code to generate random instances of given types and how  these can be combined to generate random case classes. We will analyse the properties of a ScalaCheck generator and provide examples of how we can manipulate existing generators to meet our needs. Finally, we will show how random data generation can also be used in development to restore our data-driven-application in a particular state.</p>\n","id":"WMV-8719","speakers":[{"name":"Daniela Sfregola","company":"Daniela Tech LTD","id":"5e97d05535726adc50a059c82a6e699b4696456f","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/5e97d05535726adc50a059c82a6e699b4696456f","rel":"http://cfp.scala.io/api/profile/speaker","title":"Daniela Sfregola"},"twitter":"@DanielaSfregola"}],"title":"Random Data Generation with ScalaCheck","lang":"en","summary":"ScalaCheck is a well-known library for property-base testing. However, property-base testing is not always possible when side effects are involved, for example when writing an integration test that involves data being stored in a database. When writing non-property-base tests, we often need to initialise some data and then verify some assertions on it. However, manual data generation can make our data biased and stop from spotting bugs in our code. Having our data generated randomly not only it would make our test less biased, but it will also make it a lot more readable by highlighting what part of our data are actually relevant in our test.\r\n\r\nIn this talk we will discuss how to reuse some of the existing ScalaCheck code to generate random instances of given types and how  these can be combined to generate random case classes. We will analyse the properties of a ScalaCheck generator and provide examples of how we can manipulate existing generators to meet our needs. Finally, we will show how random data generation can also be used in development to restore our data-driven-application in a particular state."},{"talkType":"Conference","track":"Type & Functional Programming","audienceLevel":"Débutant","summaryAsHtml":"<p>In this talk, we will see how to use patterns from functional programming to solve problems you know from the imperative style, but much more elegant and in a more compositonal way.</p>\n<p>We will walk through slides and code, demonstrating functional patterns e.g., Monoids with Apache Spark and the functional way of exception handling.</p>\n<p>The talk aims to serve as an introduction to patterns from functional programming and is suited for both beginner and intermediate FP enthusiasts.</p>\n","id":"KDC-6526","speakers":[{"name":"Markus Hauck","company":"codecentric AG","id":"ec5aabe71e00281b32d57b94af7685ec8b659cb8","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/ec5aabe71e00281b32d57b94af7685ec8b659cb8","rel":"http://cfp.scala.io/api/profile/speaker","title":"Markus Hauck"},"twitter":"@markus1189"}],"title":"Applying Functional Programming Patterns","lang":"en","summary":"In this talk, we will see how to use patterns from functional programming to solve problems you know from the imperative style, but much more elegant and in a more compositonal way.\r\n\r\nWe will walk through slides and code, demonstrating functional patterns e.g., Monoids with Apache Spark and the functional way of exception handling. \r\n\r\n The talk aims to serve as an introduction to patterns from functional programming and is suited for both beginner and intermediate FP enthusiasts."},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>When the data validation component  in our application is not well designed, the code can quickly become not expressive enough and probably difficult to maintain. Business rules don&#x27;t help, adding more and more requirements to add in our validation, making it more and more complex to clearly represent and maintain. At the same time when the validation fails, it should be fairly straight forward to understand why the request was rejected, so that actions can be taken accordingly.</p>\n<p>This talk introduces Cats, a Scala library based on category theory, and some of its most interesting components for data validation. In particular we&#x27;ll discuss some options to achieve efficient and expressive data validation. We will also argue that, compared to other options in the language, Cats is particularly suited for the task thanks to its easy-to-use data types and more approachable syntax.</p>\n<p>Throughout the talk, you will see numerous examples on how data validation can be achieved in a clean and robust way, and how we can easily integrate it in our code, without any specific knowledge of category theory.</p>\n","id":"BIR-9814","speakers":[{"name":"Daniela Sfregola","company":"Daniela Tech LTD","id":"5e97d05535726adc50a059c82a6e699b4696456f","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/5e97d05535726adc50a059c82a6e699b4696456f","rel":"http://cfp.scala.io/api/profile/speaker","title":"Daniela Sfregola"},"twitter":"@DanielaSfregola"}],"title":"Easy and Efficient Data Validation with Cats","lang":"en","summary":"When the data validation component  in our application is not well designed, the code can quickly become not expressive enough and probably difficult to maintain. Business rules don't help, adding more and more requirements to add in our validation, making it more and more complex to clearly represent and maintain. At the same time when the validation fails, it should be fairly straight forward to understand why the request was rejected, so that actions can be taken accordingly.\r\n\r\nThis talk introduces Cats, a Scala library based on category theory, and some of its most interesting components for data validation. In particular we'll discuss some options to achieve efficient and expressive data validation. We will also argue that, compared to other options in the language, Cats is particularly suited for the task thanks to its easy-to-use data types and more approachable syntax.\r\n\r\nThroughout the talk, you will see numerous examples on how data validation can be achieved in a clean and robust way, and how we can easily integrate it in our code, without any specific knowledge of category theory."},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>Stream processing has become ubiquitous and Akka Streams, an implementation of the Reactive Streams specification, is one of the hottest kids on the block. In this talk we quickly cover the essential basics and then introduce advanced features like cyclic graphs and custom stream processing stages. Of course we use as few slides as possible and give a lot of attention to live coding a non-trivial stream topology which reliably consumes events.</p>\n","id":"BGZ-1013","speakers":[{"name":"Heiko Seeberger","company":"codecentric","id":"9fd75fbfbf1691ee918d20edce658b3106ae82ac","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/9fd75fbfbf1691ee918d20edce658b3106ae82ac","rel":"http://cfp.scala.io/api/profile/speaker","title":"Heiko Seeberger"},"twitter":"@hseeberger"}],"title":"Learn you advanced Akka Streams for great Good!","lang":"en","summary":"Stream processing has become ubiquitous and Akka Streams, an implementation of the Reactive Streams specification, is one of the hottest kids on the block. In this talk we quickly cover the essential basics and then introduce advanced features like cyclic graphs and custom stream processing stages. Of course we use as few slides as possible and give a lot of attention to live coding a non-trivial stream topology which reliably consumes events."},{"talkType":"Conference","track":"BigData & MachineLearning","audienceLevel":"Débutant","summaryAsHtml":"<p>Ce retour d’expérience est une compilation de recettes permettant de maximiser l’usage des ressources  et d’améliorer les performances des traitements Spark et Spark Streaming.</p>\n<p>Nous partagerons à partir de Spark UI les observations qui nous ont conduit à une évolution des algorithmes et le résultat produit par la mise en oeuvre de chacune des recettes.</p>\n<p>Ces recettes nous ont notamment permis :</p>\n<ul>\n<li><p>De réduire la redistribution intempestive des données sur les noeuds du cluster (shuffling)</p>\n</li>\n<li><p>D’améliorer le niveau de parallélisme</p>\n</li>\n<li><p>De réduire l’empreinte mémoire</p>\n</li>\n<li><p>De répartir de manière équilibrée  les traitements sur les noeuds du cluster</p>\n</li>\n<li><p>D’optimiser le parallélisme par partition Kafka des applications Spark Streaming</p>\n</li>\n</ul>\n<p>Si vous aussi vous avez besoin de réduire par un facteur significatif les délais d’exécution de vos traitements Spark alors cette présentation devrait vous y aider.</p>\n","id":"IKT-0552","speakers":[{"name":"Hayssam Saleh","company":"ebiznext","id":"72e582c8d5aa96dfd49bb4e670f3b2cb073f0b73","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/72e582c8d5aa96dfd49bb4e670f3b2cb073f0b73","rel":"http://cfp.scala.io/api/profile/speaker","title":"Hayssam Saleh"},"twitter":"@hayssams"}],"title":"Recettes appliquées dans l’optimisation de Dataflow Spark","lang":"fr","summary":"Ce retour d’expérience est une compilation de recettes permettant de maximiser l’usage des ressources  et d’améliorer les performances des traitements Spark et Spark Streaming. \r\n\r\nNous partagerons à partir de Spark UI les observations qui nous ont conduit à une évolution des algorithmes et le résultat produit par la mise en oeuvre de chacune des recettes.\r\n\r\n Ces recettes nous ont notamment permis :\r\n\r\n- De réduire la redistribution intempestive des données sur les noeuds du cluster (shuffling)\r\n\r\n- D’améliorer le niveau de parallélisme \r\n\r\n- De réduire l’empreinte mémoire\r\n\r\n- De répartir de manière équilibrée  les traitements sur les noeuds du cluster\r\n\r\n- D’optimiser le parallélisme par partition Kafka des applications Spark Streaming\r\n\r\nSi vous aussi vous avez besoin de réduire par un facteur significatif les délais d’exécution de vos traitements Spark alors cette présentation devrait vous y aider.\r\n"},{"talkType":"Quickie","track":"Other Languages","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>Avant, j&#x27;utilisais beaucoup Debian pour héberger les sites de mon entreprise. Puis j&#x27;ai découvert <a href=\"https://nixos.org/\">NixOS</a>. C&#x27;est une distribution Linux construite sur les principes de l&#x27;infrastructure immuable : il y a une séparation claire entre les données variables et le reste, reste qui est géré de manière déclarative et reproductible.</p>\n<p>J&#x27;expliquerai ce qu&#x27;est NixOS, comment ça marche et pourquoi c&#x27;est un <em>game changer</em> pour moi (et peut être pour vous) !</p>\n","id":"LPF-3999","speakers":[{"name":"David Sferruzza","company":"Startup Palace / Université de Nantes","id":"5aca2c56359268bf8fd68dde1318aa1669315670","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/5aca2c56359268bf8fd68dde1318aa1669315670","rel":"http://cfp.scala.io/api/profile/speaker","title":"David Sferruzza"},"twitter":"@d_sferruzza"}],"title":"Les infrastructures immuables et la configuration déclarative ont supprimé la douleur de la gestion des serveurs !","lang":"fr","summary":"Avant, j'utilisais beaucoup Debian pour héberger les sites de mon entreprise. Puis j'ai découvert [NixOS](https://nixos.org/). C'est une distribution Linux construite sur les principes de l'infrastructure immuable : il y a une séparation claire entre les données variables et le reste, reste qui est géré de manière déclarative et reproductible.\r\n\r\nJ'expliquerai ce qu'est NixOS, comment ça marche et pourquoi c'est un *game changer* pour moi (et peut être pour vous) !"},{"talkType":"Hands-on Labs","track":"Scala & Ecosystem","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>This workshop is designed to give developers the necessary skills to start building CQRS and Event Sourced applications using Fun.CQRS.</p>\n<p>You will learn the basic principles of CQRS / ES and how to model a domain in terms of Commands and Events. We will explore some strategies that can be applied when designing aggregates (write-models) and views (read-models).</p>\n<p>If time allows we will have a deep dive into Fun.CQRS internals and explore some design choices we have made while building its interpreter and its different backends.</p>\n","id":"NOP-4669","speakers":[{"name":"Renato Cavalcanti","company":"Strong[Typed]","id":"79db15fa36183f0a64647918dd56883e5d06f745","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/79db15fa36183f0a64647918dd56883e5d06f745","rel":"http://cfp.scala.io/api/profile/speaker","title":"Renato Cavalcanti"},"twitter":"@renatocaval"}],"title":"Functional Event Sourced Applications with Fun.CQRS","lang":"en","summary":"This workshop is designed to give developers the necessary skills to start building CQRS and Event Sourced applications using Fun.CQRS.\r\n\r\nYou will learn the basic principles of CQRS / ES and how to model a domain in terms of Commands and Events. We will explore some strategies that can be applied when designing aggregates (write-models) and views (read-models).\r\n\r\nIf time allows we will have a deep dive into Fun.CQRS internals and explore some design choices we have made while building its interpreter and its different backends.\r\n"},{"talkType":"Conference","track":"Scala University","audienceLevel":"Débutant","summaryAsHtml":"<p>La programmation fonctionnelle est un sujet bien évidement très important lorsqu&#x27;on souhaite faire du Scala. Malheureusement, elle est souvent expliquée à travers des concepts trop théoriques (monades) ou de manière trop superficielle (la présence de fonctions lamdba ne suffisent pas à faire un langage de programmation fonctionnelle). Je vous aiderai à comprendre et à prendre du recul ce que c&#x27;est, et pourquoi c&#x27;est important pour construire des applications du monde réel.</p>\n<p>Nous verrons les concepts fondamentaux de la programmation fonctionnelle, comment ils s&#x27;appliquent à Scala, et pourquoi c&#x27;est top !</p>\n","id":"LQH-4260","speakers":[{"name":"David Sferruzza","company":"Startup Palace / Université de Nantes","id":"5aca2c56359268bf8fd68dde1318aa1669315670","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/5aca2c56359268bf8fd68dde1318aa1669315670","rel":"http://cfp.scala.io/api/profile/speaker","title":"David Sferruzza"},"twitter":"@d_sferruzza"}],"title":"La programmation fonctionnelle n'est pas juste les fonctions lambda !","lang":"fr","summary":"La programmation fonctionnelle est un sujet bien évidement très important lorsqu'on souhaite faire du Scala. Malheureusement, elle est souvent expliquée à travers des concepts trop théoriques (monades) ou de manière trop superficielle (la présence de fonctions lamdba ne suffisent pas à faire un langage de programmation fonctionnelle). Je vous aiderai à comprendre et à prendre du recul ce que c'est, et pourquoi c'est important pour construire des applications du monde réel.\r\n\r\nNous verrons les concepts fondamentaux de la programmation fonctionnelle, comment ils s'appliquent à Scala, et pourquoi c'est top !"},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Expert et sénior","summaryAsHtml":"<p>Most people are familiar with the <code>s&amp;quot;Hello, $name&amp;quot;</code> syntax for composing strings, but that only touches the surface of what is possible in Scala. By combining it with other advanced Scala features such as implicits and macros, we open ourselves up to numerous powerful opportunities with applications in domain-specific languages and type-level programming.</p>\n","id":"VUY-5658","speakers":[{"name":"Jon Pretty","company":"Propensive","id":"1c880401ed12cc276b0f15a351827f2ca27737af","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/1c880401ed12cc276b0f15a351827f2ca27737af","rel":"http://cfp.scala.io/api/profile/speaker","title":"Jon Pretty"},"twitter":"@propensive"}],"title":"Interpolating Strings Like A Boss","lang":"en","summary":"Most people are familiar with the `s\"Hello, $name\"` syntax for composing strings, but that only touches the surface of what is possible in Scala. By combining it with other advanced Scala features such as implicits and macros, we open ourselves up to numerous powerful opportunities with applications in domain-specific languages and type-level programming."},{"talkType":"Conference","track":"Scala University","audienceLevel":"Débutant","summaryAsHtml":"<p>Scala c&#x27;est aussi pour le front !</p>\n<p>Quand on pense Scala, on n&#x27;a pas forcement en tête la réalisation d&#x27;une <a href=\"https://fr.wikipedia.org/wiki/Application_web_monopage\">application web monopage</a> et bien si c&#x27;est possible et c&#x27;est même très bien.<br  /></p>\n<p>Dans ce talk, je montrerai comment démarrer un tel projet et comment le framework React de Facebook s&#x27;accorde particulièrement bien avec Scala.</p>\n","id":"UEJ-7721","speakers":[{"name":"Antoine Comte","company":null,"id":"0b29d1b2d36630044484be57cd5ea0fd2077650d","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/0b29d1b2d36630044484be57cd5ea0fd2077650d","rel":"http://cfp.scala.io/api/profile/speaker","title":"Antoine Comte"},"twitter":"@ant8e"}],"title":"Démarrer un project frontend avec Scala.js & React","lang":"fr","summary":"Scala c'est aussi pour le front ! \r\n\r\nQuand on pense Scala, on n'a pas forcement en tête la réalisation d'une [application web monopage](https://fr.wikipedia.org/wiki/Application_web_monopage) et bien si c'est possible et c'est même très bien.  \r\n\r\nDans ce talk, je montrerai comment démarrer un tel projet et comment le framework React de Facebook s'accorde particulièrement bien avec Scala.\r\n "},{"talkType":"Short conference","track":"BigData & MachineLearning","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>In this talk, I will present the design and implementation of LuceneRDD for Apache Spark.\nLuceneRDD instantiates an inverted index on each Spark executor and collects / aggregates search results from Spark executors to the Spark driver. The main motivation behind LuceneRDD is to <em>natively</em> extend Spark&#x27;s capabilities with full-text search, geospatial search and entity linkage without requiring an external dependency of a SolrCloud or Elasticsearch cluster.</p>\n<p>As a case study, we will show how LuceneRDD can tackle the entity linkage problem. We will demonstrate both the flexibility and efficiency of LuceneRDD for this problem.\nFirst, we will show that LuceneRDD&#x27;s interface provide a highly flexible approach to its users for entity linkage. This flexibility is  due to Lucene&#x27;s powerful query language that is able to combine multiple full-text queries such as term, prefix, fuzzy and phrase queries. Second, we will focus on the efficiency and scalability of LuceneRDD by linking records between two relatively large datasets.</p>\n<p>Lastly and time permitting, I will present ShapeLuceneRDD which enhances LuceneRDD with geospatial queries.</p>\n","id":"DOX-2319","speakers":[{"name":"Anastasios Zouzias","company":"Swisscom","id":"63fcfbdd980cf45a7e232a5a4cc04d81d79a80fd","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/63fcfbdd980cf45a7e232a5a4cc04d81d79a80fd","rel":"http://cfp.scala.io/api/profile/speaker","title":"Anastasios Zouzias"},"twitter":"@zouzias"}],"title":"LuceneRDD for (Geospatial) Search and Entity Linkage","lang":"en","summary":"In this talk, I will present the design and implementation of LuceneRDD for Apache Spark.\r\nLuceneRDD instantiates an inverted index on each Spark executor and collects / aggregates search results from Spark executors to the Spark driver. The main motivation behind LuceneRDD is to *natively* extend Spark's capabilities with full-text search, geospatial search and entity linkage without requiring an external dependency of a SolrCloud or Elasticsearch cluster.\r\n\r\nAs a case study, we will show how LuceneRDD can tackle the entity linkage problem. We will demonstrate both the flexibility and efficiency of LuceneRDD for this problem.\r\nFirst, we will show that LuceneRDD's interface provide a highly flexible approach to its users for entity linkage. This flexibility is  due to Lucene's powerful query language that is able to combine multiple full-text queries such as term, prefix, fuzzy and phrase queries. Second, we will focus on the efficiency and scalability of LuceneRDD by linking records between two relatively large datasets.\r\n\r\nLastly and time permitting, I will present ShapeLuceneRDD which enhances LuceneRDD with geospatial queries."},{"talkType":"Conference","track":"BigData & MachineLearning","audienceLevel":"Débutant","summaryAsHtml":"<p>Machine learning, classification, regression, clustering... que de bien grands mots ! Ces méthodes statistiques posent la question de l’identification de sous-populations, lesquelles baignées dans une masse complexe et hétérogène d&#x27;individus sont invisible à l&#x27;oeil nu.</p>\n<p>L&#x27;algorithme de k-means, le cas d’usage de cette présentation, permet par exemple le partitionnement d&#x27;une population en ses K sous groupes homogènes.</p>\n<p>Comment avec le code exploiter, développer et automatiser ces algorithmes ? Quelles technologies informatiques pour quels performances, quels technologies pour présenter les résultats ? Enfin, quels best-practices pour coder les aléas ?</p>\n<p>Dans cette présentation, après avoir introduit le modèle k-means, nous en détaillons l’implémentation pas à pas en Spark-Scala et discutons des optimisations possibles. Nous mettrons en exergue comment l’approche objet, fonctionnelle, et massivement parallèle portée par Spark-Scala rend possible l’intégration des différents modules mathématiques (calculs des distances, affectations aux partitions, itérations) qui compose les k-means.</p>\n","id":"MAK-0269","speakers":[{"name":"Andry Randriamanamihaga","company":"Ebiznext","id":"7017321b05efd84e1dbd591ca54624760caeb079","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/7017321b05efd84e1dbd591ca54624760caeb079","rel":"http://cfp.scala.io/api/profile/speaker","title":"Andry Randriamanamihaga"},"twitter":null}],"title":"Du matheux au codeur ? Guide de développement d'un modèle de machine Learning en Scala. Cas d'usage: algorithme des k-means","lang":"fr","summary":"Machine learning, classification, regression, clustering... que de bien grands mots ! Ces méthodes statistiques posent la question de l’identification de sous-populations, lesquelles baignées dans une masse complexe et hétérogène d'individus sont invisible à l'oeil nu. \r\n\r\nL'algorithme de k-means, le cas d’usage de cette présentation, permet par exemple le partitionnement d'une population en ses K sous groupes homogènes.\r\n\r\nComment avec le code exploiter, développer et automatiser ces algorithmes ? Quelles technologies informatiques pour quels performances, quels technologies pour présenter les résultats ? Enfin, quels best-practices pour coder les aléas ?\r\n\r\nDans cette présentation, après avoir introduit le modèle k-means, nous en détaillons l’implémentation pas à pas en Spark-Scala et discutons des optimisations possibles. Nous mettrons en exergue comment l’approche objet, fonctionnelle, et massivement parallèle portée par Spark-Scala rend possible l’intégration des différents modules mathématiques (calculs des distances, affectations aux partitions, itérations) qui compose les k-means. "},{"talkType":"Short conference","track":"Other Languages","audienceLevel":"Débutant","summaryAsHtml":"<p>Idris est un langage inspiré fonctionnel pur implémentant le paradigme du typage dépendant permettant d&#x27;utiliser des valeurs dans les types.</p>\n<p>Cette session, principalement sous forme de live-coding, sera l&#x27;occasion de découvrir Idris et ses particularités par rapport à Scala. On y parlera donc typage dépendant,  preuves et génération de code dirigé par les types.</p>\n","id":"STK-9875","speakers":[{"name":"Benoit Lemoine","company":"Captain Dash","id":"ef8933bb26512f3a7aeef3f40998269f9705d053","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/ef8933bb26512f3a7aeef3f40998269f9705d053","rel":"http://cfp.scala.io/api/profile/speaker","title":"Benoit Lemoine"},"twitter":"@benoit_lemoine"}],"title":"À la découverte d'Idris et de ses types dépendants","lang":"fr","summary":" Idris est un langage inspiré fonctionnel pur implémentant le paradigme du typage dépendant permettant d'utiliser des valeurs dans les types.\r\n \r\nCette session, principalement sous forme de live-coding, sera l'occasion de découvrir Idris et ses particularités par rapport à Scala. On y parlera donc typage dépendant,  preuves et génération de code dirigé par les types. \r\n"},{"talkType":"Hands-on Labs","track":"Type & Functional Programming","audienceLevel":"Débutant","summaryAsHtml":"<p>Parser des fichiers avec des parser combinators, des foncteurs applicatifs et des monades : des mots compliqués pour faire du code plus simple !</p>\n<p>Les parser combinators sont très populaires pour écrire des parseurs dans les langages fonctionnels. Cette initiation présentera les principes de base des parser combinators, en utilisant Scala, mais indépendamment d&#x27;une librairie ou d&#x27;un langage en particulier. Au passage, nous découvrirons que les parseurs sont un bon sujet pour parler de concepts de théorie des catégories (foncteurs, foncteurs applicatifs, et monades) de manière purement pratique.</p>\n","id":"RFK-3199","speakers":[{"name":"Georges Dubus","company":"AXA — Data Innovation Lab","id":"bb335ce342b0e618612884c91f39217c187a3407","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/bb335ce342b0e618612884c91f39217c187a3407","rel":"http://cfp.scala.io/api/profile/speaker","title":"Georges Dubus"},"twitter":"@georgesdubus"}],"title":"Parser des fichiers avec des parser combinators ! ","lang":"fr","summary":"Parser des fichiers avec des parser combinators, des foncteurs applicatifs et des monades : des mots compliqués pour faire du code plus simple ! \r\n\r\nLes parser combinators sont très populaires pour écrire des parseurs dans les langages fonctionnels. Cette initiation présentera les principes de base des parser combinators, en utilisant Scala, mais indépendamment d'une librairie ou d'un langage en particulier. Au passage, nous découvrirons que les parseurs sont un bon sujet pour parler de concepts de théorie des catégories (foncteurs, foncteurs applicatifs, et monades) de manière purement pratique. "},{"talkType":"Short conference","track":"BigData & MachineLearning","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>L&#x27;un des avantages de Scalding, la bibliothèque de Twitter pour développer en Scala des applications fondées sur Hadoop, est qu&#x27;elle s&#x27;appuie sur Cascading. Or, ce dernier utilise désormais le concept de &quot;fabric&quot; afin d&#x27;abstraire l&#x27;environnement d&#x27;exécution.</p>\n<p>Nous vous montrerons comment nos performances ont été améliorées de 50% à l&#x27;aide de Cascading 3, en nous débarrassant de MapReduce en faveur d&#x27;Apache Tez. Nous expliquerons comment nous avons ouvert la voie pour la migration depuis MapReduce vers la nouvelle génération d&#x27;outils (Tez, Spark, Storm, Flink).</p>\n","id":"OZV-8736","speakers":[{"name":"Sylvain Veyrié","company":"Transparency Rights Management","id":"2d809da647eee11716b01ffd461d22b32f04e890","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/2d809da647eee11716b01ffd461d22b32f04e890","rel":"http://cfp.scala.io/api/profile/speaker","title":"Sylvain Veyrié"},"twitter":null},{"name":"Cyrille Chépélov","company":"Transparency Rights Management","id":"b3078693011bf3ae1fa0c197c6e59cf23a7f23f8","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/b3078693011bf3ae1fa0c197c6e59cf23a7f23f8","rel":"http://cfp.scala.io/api/profile/speaker","title":"Cyrille Chépélov"},"twitter":"@c_chep"}],"title":"Scalding + Cascading + TEZ = ♥","lang":"fr","summary":"L'un des avantages de Scalding, la bibliothèque de Twitter pour développer en Scala des applications fondées sur Hadoop, est qu'elle s'appuie sur Cascading. Or, ce dernier utilise désormais le concept de \"fabric\" afin d'abstraire l'environnement d'exécution.\r\n\r\nNous vous montrerons comment nos performances ont été améliorées de 50% à l'aide de Cascading 3, en nous débarrassant de MapReduce en faveur d'Apache Tez. Nous expliquerons comment nous avons ouvert la voie pour la migration depuis MapReduce vers la nouvelle génération d'outils (Tez, Spark, Storm, Flink)."},{"talkType":"Short conference","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>I&#x27;ve seen all walks of Scala engineering life, and an equal number of interesting companies seeking to use the tech-stack. Learning/Knowing/Growing the technology is typically of primary importance to it&#x27;s users, but beyond advancing the stack - what is it being used for in the real world, what does the future hold for the Scala community at large - and how can we affect that?</p>\n","id":"WKU-9477","speakers":[{"name":"Michael Cohen","company":"Continuity Partners, Inc. (CPI)","id":"c63fcf3d4f6711ddde42f79637d4bc3c8a4bcd00","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/c63fcf3d4f6711ddde42f79637d4bc3c8a4bcd00","rel":"http://cfp.scala.io/api/profile/speaker","title":"Michael Cohen"},"twitter":"@GothamTechTalk"}],"title":"The Real Scala Engineers of Planet Earth ","lang":"en","summary":"I've seen all walks of Scala engineering life, and an equal number of interesting companies seeking to use the tech-stack. Learning/Knowing/Growing the technology is typically of primary importance to it's users, but beyond advancing the stack - what is it being used for in the real world, what does the future hold for the Scala community at large - and how can we affect that? "},{"talkType":"Short conference","track":"Scala University","audienceLevel":"Débutant","summaryAsHtml":"<p>L&#x27;injection de dépendances est une pratique bien connue dans le développement d&#x27;applications car elle permet de conserver un code plus lisible, plus réutilisable et plus testable.</p>\n<p>La richesse du langage Scala rend possible son implémentation sans aucun additif mais il existe également d&#x27;autres approches. Cette présentation décrit quelques-unes d&#x27;entre-elles au travers d&#x27;exemples et de retours d&#x27;expérience pour évaluer leurs avantages et leurs limites et identifier celles à privilégier.</p>\n","id":"SAC-1682","speakers":[{"name":"Simon Dumas","company":"Ebiznext","id":"96a0ec8e171bd3935311935a486ec959c157d521","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/96a0ec8e171bd3935311935a486ec959c157d521","rel":"http://cfp.scala.io/api/profile/speaker","title":"Simon Dumas"},"twitter":"@_sdumas_"}],"title":"Comment bien choisir son approche d’injection de dépendances ?","lang":"fr","summary":"L'injection de dépendances est une pratique bien connue dans le développement d'applications car elle permet de conserver un code plus lisible, plus réutilisable et plus testable.\r\n\r\nLa richesse du langage Scala rend possible son implémentation sans aucun additif mais il existe également d'autres approches. Cette présentation décrit quelques-unes d'entre-elles au travers d'exemples et de retours d'expérience pour évaluer leurs avantages et leurs limites et identifier celles à privilégier."},{"talkType":"Short conference","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>Pour réaliser cette recette, vous aurez besoin de:</p>\n<ul>\n<li>Apache Kafka: un système de messaging basé sur le concept de journal de log distribué</li>\n<li>Akka: la boite à outils quasiment incontournable sur la JVM pour la création d&#x27;applications efficaces et hautement concurrentes.</li>\n</ul>\n<p>Mélangez le tout, jouez avec les threads et les garanties de livraisons, les commits.</p>\n<p>Vous devriez alors obtenir une plateforme élastique de reporting pour des transactions provenant de terminaux de paiements.</p>\n<p>Venez découvrir les deux ans de l&#x27;histoire de cette plateforme, des difficultés rencontrées, en passant du code à la solution de monitoring.</p>\n","id":"XMD-4682","speakers":[{"name":"Xavier BUCCHIOTTY","company":"Teads","id":"51145fe8e015a016bc4855c9ed9ee856d4ed09c3","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/51145fe8e015a016bc4855c9ed9ee856d4ed09c3","rel":"http://cfp.scala.io/api/profile/speaker","title":"Xavier BUCCHIOTTY"},"twitter":"@xbucchiotty"}],"title":"Bref, j'ai essayé de faire \"Reactive Kafka\"","lang":"fr","summary":"Pour réaliser cette recette, vous aurez besoin de:\r\n\r\n* Apache Kafka: un système de messaging basé sur le concept de journal de log distribué\r\n* Akka: la boite à outils quasiment incontournable sur la JVM pour la création d'applications efficaces et hautement concurrentes.\r\n\r\nMélangez le tout, jouez avec les threads et les garanties de livraisons, les commits.\r\n\r\nVous devriez alors obtenir une plateforme élastique de reporting pour des transactions provenant de terminaux de paiements.\r\n\r\nVenez découvrir les deux ans de l'histoire de cette plateforme, des difficultés rencontrées, en passant du code à la solution de monitoring.\r\n"},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>Un virus a contaminé l&#x27;équipe Hamak : l&#x27;<strong>event sourcing</strong></p>\n<ul>\n<li>Quelles sont les briques techniques  de cette architecture,</li>\n<li>Comment une requête à l&#x27;API se transforme en évènements,</li>\n<li>Les avantages d&#x27;une approche évènementielle,</li>\n<li>Des exemples de codes avant et après,</li>\n<li>Le retour d&#x27;expérience 18 mois plus tard (point de vue OPS et DEV)</li>\n</ul>\n","id":"UUP-9650","speakers":[{"name":"Damien Gouyette","company":"Freelance","id":"f9fc65391600558c83fb666fc85b81b17a5d4e7c","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/f9fc65391600558c83fb666fc85b81b17a5d4e7c","rel":"http://cfp.scala.io/api/profile/speaker","title":"Damien Gouyette"},"twitter":"@cestpasdur"},{"name":"Valentin Kasas","company":null,"id":"23f8248fbc844d21d1475f1a7a6b945ff6e1f058","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/23f8248fbc844d21d1475f1a7a6b945ff6e1f058","rel":"http://cfp.scala.io/api/profile/speaker","title":"Valentin Kasas"},"twitter":null}],"title":"CQRS  + ES > CRUD, CQFD ","lang":"fr","summary":"Un virus a contaminé l'équipe Hamak : l'**event sourcing** \r\n\r\n* Quelles sont les briques techniques  de cette architecture,\r\n* Comment une requête à l'API se transforme en évènements,\r\n* Les avantages d'une approche évènementielle,\r\n* Des exemples de codes avant et après,\r\n* Le retour d'expérience 18 mois plus tard (point de vue OPS et DEV)"},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>Typeclasses are widely in use on advanced Scala code and yet they are not a first class citizen of the language. This talk will introduce the concept of typeclasses from the ground up by looking at languages such as Haskell and Rust.</p>\n<p>Typeclass coherence (multiple instances of the same typeclass for the same type), effective namespacing and implicit resolution (in Scala) are some of the challenges that arise for extensive usage of this concept and language feature. We&#x27;ll explore those issues and how other languages deal with them.</p>\n<p>The focus will then shift on how to apply the learnings from other languages to improve the readability and usability of typeclasses in Scala via conventions and reliance on tools such as macro annotations. The <em>Cats</em> and <em>Simulacrum</em> libraries, among others, will serve as case studies and examples.</p>\n","id":"XLE-7871","speakers":[{"name":"Andrea Lattuada","company":null,"id":"938ee038670fe7ad90c7b294b9d63e738f051bcd","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/938ee038670fe7ad90c7b294b9d63e738f051bcd","rel":"http://cfp.scala.io/api/profile/speaker","title":"Andrea Lattuada"},"twitter":"@utaal"}],"title":"Typeclasses — a type system construct","lang":"en","summary":"Typeclasses are widely in use on advanced Scala code and yet they are not a first class citizen of the language. This talk will introduce the concept of typeclasses from the ground up by looking at languages such as Haskell and Rust.\r\n\r\nTypeclass coherence (multiple instances of the same typeclass for the same type), effective namespacing and implicit resolution (in Scala) are some of the challenges that arise for extensive usage of this concept and language feature. We'll explore those issues and how other languages deal with them.\r\n\r\nThe focus will then shift on how to apply the learnings from other languages to improve the readability and usability of typeclasses in Scala via conventions and reliance on tools such as macro annotations. The _Cats_ and _Simulacrum_ libraries, among others, will serve as case studies and examples.\r\n"},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>Scala language has a lot of amazing features like type safety, pattern matching, recursion, lambdas and other functional things combined together in a way that makes developer happier.</p>\n<p>But all these dreams about functional magic can be easily broken by the cases like &quot;when I rewrote all my spaghetti Java code to a Scala one-liner, why did it become three times slower?&quot;. Harsh reality shows us that all these modern high-level abstractions may hide monsters inside and a comfort you get by using them comes at a price. So if you develop something more complex than a simple CRUD application and it&#x27;s even slightly connected with performance, you have to clearly understand how all these &quot;monads&quot; behave under the hood.</p>\n<p>This talk will tell you about a magic performed by the scala compiler, show a couple of horror stories about scala application performance with explanations and solutions:</p>\n<ul>\n<li>What happens when you hit &#x27;compile &amp; run&#x27; button.</li>\n<li>Pattern-matching, tail recursion and collections case stories.</li>\n<li>JMH and how to use it with your Scala code.</li>\n<li>How HotSpot optimises your code.</li>\n</ul>\n<p>... and a bit more about Scala 2.12 improvements.</p>\n","id":"PHF-4907","speakers":[{"name":"Roman Grebennikov","company":"Findify","id":"88c281ed083dacc8af5ae40d633b9b977e4fd339","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/88c281ed083dacc8af5ae40d633b9b977e4fd339","rel":"http://cfp.scala.io/api/profile/speaker","title":"Roman Grebennikov"},"twitter":"@public_void_grv"}],"title":"Is scala code slow?","lang":"en","summary":"Scala language has a lot of amazing features like type safety, pattern matching, recursion, lambdas and other functional things combined together in a way that makes developer happier. \r\n\r\nBut all these dreams about functional magic can be easily broken by the cases like \"when I rewrote all my spaghetti Java code to a Scala one-liner, why did it become three times slower?\". Harsh reality shows us that all these modern high-level abstractions may hide monsters inside and a comfort you get by using them comes at a price. So if you develop something more complex than a simple CRUD application and it's even slightly connected with performance, you have to clearly understand how all these \"monads\" behave under the hood.\r\n\r\nThis talk will tell you about a magic performed by the scala compiler, show a couple of horror stories about scala application performance with explanations and solutions:\r\n\r\n* What happens when you hit 'compile & run' button.\r\n* Pattern-matching, tail recursion and collections case stories.\r\n* JMH and how to use it with your Scala code.\r\n* How HotSpot optimises your code.\r\n\r\n... and a bit more about Scala 2.12 improvements."},{"talkType":"Conference","track":"Type & Functional Programming","audienceLevel":"Débutant","summaryAsHtml":"<p>Shapeless is an advanced functional programming language for the scala language. Some basic features of the language will be presented (<code>Heterogenous Lists</code>, <code>The Generic[T] object</code>, <code>Polymorphic functions</code>, <code>Natural Transformations</code>, <code>Type-Level Recursion</code>, <code>Product</code>, <code>Coproduct</code>,<code>Singleton type</code>, <code>Labelledgeneric</code>) and I will code a small example on how to convert the parameters of a case class to a map using shapeless.</p>\n","id":"REZ-2037","speakers":[{"name":"Harry Laoulakos","company":"Lunatech","id":"b3e01a349f1eb483384fcb27102073b9aa62861e","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/b3e01a349f1eb483384fcb27102073b9aa62861e","rel":"http://cfp.scala.io/api/profile/speaker","title":"Harry Laoulakos"},"twitter":"@mermigx"}],"title":"Shapeless 101: A smooth introduction","lang":"en","summary":"Shapeless is an advanced functional programming language for the scala language. Some basic features of the language will be presented (`Heterogenous Lists`, `The Generic[T] object`, `Polymorphic functions`, `Natural Transformations`, `Type-Level Recursion`, `Product`, `Coproduct`,` Singleton type`, `Labelledgeneric`) and I will code a small example on how to convert the parameters of a case class to a map using shapeless. "},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>Les APIs Hypermedias ont de nombreuses propriétés intéressantes tels que la découvrabilité, l&#x27;auto-documentation et l&#x27;interoperabilité. Elles sont, cependant, encore aujourd&#x27;hui, complexes à développer.</p>\n<p>Lors de cette conférence nous étudierons les différents concepts et techniques permettant de traiter :</p>\n<ul>\n<li>La définition du domaine : Sémantique, Relations et Validations</li>\n<li>La définition des ressources : Opérations et Cycle de vie</li>\n<li>La définition du protocole</li>\n</ul>\n<p>Un exemple concret du front au back sera présenté pour clôturer la présentation.</p>\n","id":"DYN-2992","speakers":[{"name":"Antoine Michel","company":"Zengularity","id":"600210c433b497bca4d3a3352354ef3417a50873","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/600210c433b497bca4d3a3352354ef3417a50873","rel":"http://cfp.scala.io/api/profile/speaker","title":"Antoine Michel"},"twitter":null}],"title":"Développer des APIs Hypermedias simplement avec Scala","lang":"fr","summary":"Les APIs Hypermedias ont de nombreuses propriétés intéressantes tels que la découvrabilité, l'auto-documentation et l'interoperabilité. Elles sont, cependant, encore aujourd'hui, complexes à développer.\r\n\r\nLors de cette conférence nous étudierons les différents concepts et techniques permettant de traiter :\r\n\r\n-  La définition du domaine : Sémantique, Relations et Validations\r\n-  La définition des ressources : Opérations et Cycle de vie\r\n-  La définition du protocole\r\n\r\nUn exemple concret du front au back sera présenté pour clôturer la présentation."},{"talkType":"Quickie","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>As domain driven design practitioners, we have to design datastructures a lot.\nOften we have to encode our knowledge into a not-so-expressive type system.\nThat&#x27;s when the trouble starts: our types don&#x27;t represent exactly what we have.</p>\n<p>Algebraic Data Types (or ADTs) are a very powerful tool and help a lot when it\ncomes to design our data types. Moreover, they share interesting properties\nwith addition and multiplication (hence their name).</p>\n<p>In this short talk, I&#x27;ll show you how to use them in scala and javascript, and\nhow their mathematical properties can give you intuition and easy\n(re)factoring.</p>\n","id":"BVR-5747","speakers":[{"name":"Clément Delafargue","company":"Clever Cloud","id":"ad36032dfb473504555950435795ac48292b8a09","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/ad36032dfb473504555950435795ac48292b8a09","rel":"http://cfp.scala.io/api/profile/speaker","title":"Clément Delafargue"},"twitter":"@clementd"}],"title":"Algebraic data types for fun and profit","lang":"en","summary":"As domain driven design practitioners, we have to design datastructures a lot.\r\nOften we have to encode our knowledge into a not-so-expressive type system.\r\nThat's when the trouble starts: our types don't represent exactly what we have.\r\n\r\nAlgebraic Data Types (or ADTs) are a very powerful tool and help a lot when it\r\ncomes to design our data types. Moreover, they share interesting properties\r\nwith addition and multiplication (hence their name).\r\n\r\nIn this short talk, I'll show you how to use them in scala and javascript, and\r\nhow their mathematical properties can give you intuition and easy\r\n(re)factoring.\r\n"},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>Vous voulez faire du streaming dans une architecture réactive ? Vous avez besoin d&#x27;implémenter un protocole TCP ? Vous  avez besoin d&#x27;un serveur HTTP léger pour une API ? D&#x27;un client pour attaquer facilement cette API ?</p>\n<p>Aujourd&#x27;hui le framework d&#x27;acteur Akka, est devenu incontournable avec son intégration dans notamment dans Play!. Mais au fait, quelles en sont toutes ses possibilités ?</p>\n<p>Venez découvrir différents cas d&#x27;utilisations réels au travers d&#x27;un REX sur un projet existant dans une architecture réactive basée sur des microservices !</p>\n","id":"CKB-8566","speakers":[{"name":"Fabian GUTIERREZ","company":"Xebia","id":"a6208a7048923c1beee531abfe7951f157917bae","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/a6208a7048923c1beee531abfe7951f157917bae","rel":"http://cfp.scala.io/api/profile/speaker","title":"Fabian GUTIERREZ"},"twitter":"@FabGutierr"},{"name":"Joachim Rousseau","company":"Xebia","id":"872165d38b75a5148e949fa31a39e43395fdcc32","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/872165d38b75a5148e949fa31a39e43395fdcc32","rel":"http://cfp.scala.io/api/profile/speaker","title":"Joachim Rousseau"},"twitter":"@__jro"}],"title":"REX akka dans une architecture microservice","lang":"fr","summary":"Vous voulez faire du streaming dans une architecture réactive ? Vous avez besoin d'implémenter un protocole TCP ? Vous  avez besoin d'un serveur HTTP léger pour une API ? D'un client pour attaquer facilement cette API ?\r\n\r\nAujourd'hui le framework d'acteur Akka, est devenu incontournable avec son intégration dans notamment dans Play!. Mais au fait, quelles en sont toutes ses possibilités ?\r\n\r\nVenez découvrir différents cas d'utilisations réels au travers d'un REX sur un projet existant dans une architecture réactive basée sur des microservices !"},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>Is it possible to generate the native x86_64 code for a Scala function at runtime? Of course it is! In this live coding session I will create a dynamic x86_64 assembler in Scala. I will start by finding a good way to embed ASM instructions into plain Scala code, generating the machine code at runtime, loading it in memory, making it executable, and finally casting it to a proper Scala function type. Is it a good idea to do this? In any case, it is a very interesting journey through Scala, external DSL and the JVM FFI.</p>\n","id":"PIJ-5037","speakers":[{"name":"Guillaume Bort","company":"Criteo","id":"02cfbdc6451fad13a43231d094448b91b038af14","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/02cfbdc6451fad13a43231d094448b91b038af14","rel":"http://cfp.scala.io/api/profile/speaker","title":"Guillaume Bort"},"twitter":"@guillaumebort"}],"title":"Writing a dynamic x86_64 assembler in Scala","lang":"fr","summary":"Is it possible to generate the native x86\\_64 code for a Scala function at runtime? Of course it is! In this live coding session I will create a dynamic x86\\_64 assembler in Scala. I will start by finding a good way to embed ASM instructions into plain Scala code, generating the machine code at runtime, loading it in memory, making it executable, and finally casting it to a proper Scala function type. Is it a good idea to do this? In any case, it is a very interesting journey through Scala, external DSL and the JVM FFI."},{"talkType":"Conference","track":"Other Languages","audienceLevel":"Débutant","summaryAsHtml":"<p>Elm est un langage simple pour écrire des applications web riches et robustes. Elm génère du JavaScript performant et surtout sans exceptions à l&#x27;exécution. Dans cette présentation, il s&#x27;agit d&#x27;introduire le langage, ses choix d&#x27;architecture, l&#x27;opposer à Scala.js et surtout montrer l&#x27;intérêt de l&#x27;utiliser dans une application web Play grâce au plugin sbt-elm.</p>\n","id":"BTX-0538","speakers":[{"name":"Choucri FAHED","company":"Finstack","id":"1b9cb5a81dc1a67865a13a49e3eb6d552a89455f","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/1b9cb5a81dc1a67865a13a49e3eb6d552a89455f","rel":"http://cfp.scala.io/api/profile/speaker","title":"Choucri FAHED"},"twitter":"@choucrifahed"}],"title":"Play with Elm!","lang":"fr","summary":"Elm est un langage simple pour écrire des applications web riches et robustes. Elm génère du JavaScript performant et surtout sans exceptions à l'exécution. Dans cette présentation, il s'agit d'introduire le langage, ses choix d'architecture, l'opposer à Scala.js et surtout montrer l'intérêt de l'utiliser dans une application web Play grâce au plugin sbt-elm."},{"talkType":"Conference","track":"Type & Functional Programming","audienceLevel":"Débutant","summaryAsHtml":"<p>Type Level Programming is currently a hot topic in the Scala community. For many people that have not invested a significant amount of time to understand this stuff, this style of programming probably seems crazy, totally unreadable, super difficult and therefore very intimidating to them. With this talk i will try to give people a smooth start into this topic. This is achieved by translating 3 simple value level programs into type level programs.</p>\n","id":"MNF-3529","speakers":[{"name":"Marcus Böhm","company":"Microsoft","id":"a08f76c68fdb1a753e13e4f3691371eb1e588d85","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/a08f76c68fdb1a753e13e4f3691371eb1e588d85","rel":"http://cfp.scala.io/api/profile/speaker","title":"Marcus Böhm"},"twitter":"@mavilein"}],"title":"A gentle introduction to Type Level Programming in Scala","lang":"en","summary":"Type Level Programming is currently a hot topic in the Scala community. For many people that have not invested a significant amount of time to understand this stuff, this style of programming probably seems crazy, totally unreadable, super difficult and therefore very intimidating to them. With this talk i will try to give people a smooth start into this topic. This is achieved by translating 3 simple value level programs into type level programs."},{"talkType":"Conference","track":"Type & Functional Programming","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>[A la demande générale, la présentation sera en FRENCH avec slides ENGLISH]</p>\n<p>Dans cette présentation, nous ne passerons pas beaucoup de temps sur la théorie mathématique mais nous expliquerons surtout la démarche théorique &amp; intellectuelle qui mène à vouloir goûter des Free Monads dans nos applications.\nPuis, nous verrons comment construire simplement une application &quot;réaliste&quot; à partir de ce concept en découplant totalement la logique métier de son exécution et en se facilitant la vie avec la librairie Freek.</p>\n<p>Nous évoquerons également les limitations potentielles de ce type d&#x27;approche et les évolutions futures ainsi que les améliorations récentes de scalac qui nous simplifient beaucoup la vie.</p>\n<p>Si le temps le permet, nous dégusterons ensemble quelques cas plus savoureux et épicés...</p>\n","id":"EMQ-3470","speakers":[{"name":"Pascal Voitot","company":"Project September","id":"be555ae598693fafb12d5ca7b893757420e653b8","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/be555ae598693fafb12d5ca7b893757420e653b8","rel":"http://cfp.scala.io/api/profile/speaker","title":"Pascal Voitot"},"twitter":"@mandubian"}],"title":"Bake real-life apps with a handful of Free, Coproducts & Types, a sip of SI2712 & some Onions","lang":"fr","summary":"[A la demande générale, la présentation sera en FRENCH avec slides ENGLISH]\r\n\r\nDans cette présentation, nous ne passerons pas beaucoup de temps sur la théorie mathématique mais nous expliquerons surtout la démarche théorique & intellectuelle qui mène à vouloir goûter des Free Monads dans nos applications.\r\nPuis, nous verrons comment construire simplement une application \"réaliste\" à partir de ce concept en découplant totalement la logique métier de son exécution et en se facilitant la vie avec la librairie Freek.\r\n\r\nNous évoquerons également les limitations potentielles de ce type d'approche et les évolutions futures ainsi que les améliorations récentes de scalac qui nous simplifient beaucoup la vie.\r\n\r\nSi le temps le permet, nous dégusterons ensemble quelques cas plus savoureux et épicés...\r\n"},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Débutant","summaryAsHtml":"<p>Scala is a powerful language. With its flexible and expressive syntax - concise yet not terse - even a single line of Scala can leverage an impressive amount of JVM power. It is the static language that feels dynamic.</p>\n<p>In this fun and engaging interactive talk (entirely live from the Scala REPL), I present dozens of Scala snippets that show us how to get dynamic productivity in a statically typed language.</p>\n<p>It is not about short or overly clever code. It&#x27;s about writing clear and elegant code.</p>\n<p>Bring your REPL!</p>\n","id":"ATD-0204","speakers":[{"name":"Marconi Lanna","company":"Originate","id":"6c6e2c83079550ad82e643217506495b9cf3ed04","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/6c6e2c83079550ad82e643217506495b9cf3ed04","rel":"http://cfp.scala.io/api/profile/speaker","title":"Marconi Lanna"},"twitter":"@ScalaFacts"}],"title":"Beautiful Scala","lang":"en","summary":"Scala is a powerful language. With its flexible and expressive syntax - concise yet not terse - even a single line of Scala can leverage an impressive amount of JVM power. It is the static language that feels dynamic.\r\n\r\nIn this fun and engaging interactive talk (entirely live from the Scala REPL), I present dozens of Scala snippets that show us how to get dynamic productivity in a statically typed language.\r\n\r\nIt is not about short or overly clever code. It's about writing clear and elegant code.\r\n\r\nBring your REPL!"},{"talkType":"Conference","track":"Scala & Ecosystem","audienceLevel":"Intermédiaire","summaryAsHtml":"<p>Testing is important for any system you write and at eBay it is no different. We have a number of complex Scala and Akka based applications with a large number of external dependencies. One of the challenges of testing this kind of application is replicating the complete system across all your environments: development, different flavors of testing (unit, functional, integration, capacity and acceptance) and production. This is especially true in the case of integration and capacity testing where there are a multitude of ways to manage system complexity. Wouldn’t it be nice to define the testing system architecture in one place that we can reuse in all our tests? It turns out we can do exactly that using Docker. In this talk, we will first look at how to take advantage of Docker for integration testing your Scala application. After that we will explore how this has helped us reduce the duration and complexity of our tests.</p>\n","id":"YNG-2515","speakers":[{"name":"Daniel Brown","company":null,"id":"5216ffabfae0e20fd1b93005a44e7d26149bfe06","link":{"href":"http://cfp.scala.io/api/conferences/ScalaIOFR2016/speakers/5216ffabfae0e20fd1b93005a44e7d26149bfe06","rel":"http://cfp.scala.io/api/profile/speaker","title":"Daniel Brown"},"twitter":null}],"title":"Scala, Docker and Testing, oh my!","lang":"en","summary":"Testing is important for any system you write and at eBay it is no different. We have a number of complex Scala and Akka based applications with a large number of external dependencies. One of the challenges of testing this kind of application is replicating the complete system across all your environments: development, different flavors of testing (unit, functional, integration, capacity and acceptance) and production. This is especially true in the case of integration and capacity testing where there are a multitude of ways to manage system complexity. Wouldn’t it be nice to define the testing system architecture in one place that we can reuse in all our tests? It turns out we can do exactly that using Docker. In this talk, we will first look at how to take advantage of Docker for integration testing your Scala application. After that we will explore how this has helped us reduce the duration and complexity of our tests."}]